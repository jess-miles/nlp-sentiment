{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW OF OSEMiN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/jirvingphd/fsds_100719_cohort_notes/master/images/OSEMN.png' width=800>\n",
    "\n",
    "<center><a href=\"https://www.kdnuggets.com/2018/02/data-science-command-line-book-exploring-data.html\"> \n",
    "    </a></center>\n",
    "\n",
    "\n",
    "> <font size=2em>The Data Science Process we'll be using during this section--OSEMiN (pronounced \"OH-sum\", rhymes with \"possum\").  This is the most straightforward of the Data Science Processes discussed so far.  **Note that during this process, just like the others, the stages often blur together.***  It is completely acceptable (and ***often a best practice!) to float back and forth** between stages as you learn new things about your problem, dataset, requirements, etc.  \n",
    "It's quite common to get to the modeling step and realize that you need to scrub your data a bit more or engineer a different feature and jump back to the \"Scrub\" stage, or go all the way back to the \"Obtain\" stage when you realize your current data isn't sufficient to solve this problem. \n",
    "As with any of these frameworks, *OSEMiN is meant to be treated as guidelines, not law. \n",
    "</font>\n",
    "\n",
    "\n",
    "### OSEMN DETAILS\n",
    "\n",
    "**OBTAIN**\n",
    "\n",
    "- This step involves understanding stakeholder requirements, gathering information on the problem, and finally sourcing data that we think will be necessary for solving this problem. \n",
    "\n",
    "**SCRUB**\n",
    "\n",
    "- During this stage, we'll focus on preprocessing our data.  Important steps such as identifying and removing null values, dealing with outliers, normalizing data, and feature engineering/feature selection are handled around this stage.  The line with this stage really blurs with the _Explore_ stage, as it is common to only realize that certain columns require cleaning or preprocessing as a result of the visualzations and explorations done during Step 3.  \n",
    "\n",
    "- Note that although technically, categorical data should be one-hot encoded during this step, in practice, it's usually done after data exploration.  This is because it is much less time-consuming to visualize and explore a few columns containing categorical data than it is to explore many different dummy columns that have been one-hot encoded. \n",
    "\n",
    "**EXPLORE**\n",
    "\n",
    "- This step focuses on getting to know the dataset you're working with. As mentioned above, this step tends to blend with the _Scrub_ step mentioned above.  During this step, you'll create visualizations to really get a feel for your dataset.  You'll focus on things such as understanding the distribution of different columns, checking for multicollinearity, and other tasks liek that.  If your project is a classification task, you may check the balance of the different classes in your dataset.  If your problem is a regression task, you may check that the dataset meets the assumptions necessary for a regression task.  \n",
    "\n",
    "- At the end of this step, you should have a dataset ready for modeling that you've thoroughly explored and are extremely familiar with.  \n",
    "\n",
    "**MODEL**\n",
    "\n",
    "- This step, as with the last two frameworks, is also pretty self-explanatory. It consists of building and tuning models using all the tools you have in your data science toolbox.  In practice, this often means defining a threshold for success, selecting machine learning algorithms to test on the project, and tuning the ones that show promise to try and increase your results.  As with the other stages, it is both common and accepted to realize something, jump back to a previous stage like _Scrub_ or _Explore_, and make some changes to see how it affects the model.  \n",
    "\n",
    "**iNTERPRET**\n",
    "\n",
    "- During this step, you'll interpret the results of your model(s), and communicate results to stakeholders.  As with the other frameworks, communication is incredibily important! During this stage, you may come to realize that further investigation is needed, or more data.  That's totally fine--figure out what's needed, go get it, and start the process over! If your results are satisfactory to all stakeholders involved, you may also go from this stage right into productionizing your model and automating processes necessary to support it.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS CHECKLIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Keep in mind that it is normal to jump between the OSEMN phases and some of them will blend together, like SCRUB and EXPLORE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[OBTAIN](#OBTAIN)**\n",
    "    - Import data, inspect, check for datatypes to convert and null values\n",
    "    - Display header and info.\n",
    "    - Drop any unneeded columns, if known (`df.drop(['col1','col2'],axis=1,inplace=True`)\n",
    "    <br><br>\n",
    "\n",
    "\n",
    "2. **[SCRUB](#SCRUB)**\n",
    "    - Recast data types, identify outliers, check for multicollinearity, normalize data**\n",
    "    - Check and cast data types\n",
    "        - [ ] Check for #'s that are store as objects (`df.info()`,`df.describe()`)\n",
    "            - when converting to #'s, look for odd values (like many 0's), or strings that can't be converted.\n",
    "            - Decide how to deal weird/null values (`df.unique()`, `df.isna().sum()`)\n",
    "            - `df.fillna(subset=['col_with_nulls'],'fill_value')`, `df.replace()`\n",
    "        - [ ] Check for categorical variables stored as integers.\n",
    "            - May be easier to tell when you make a scatter plotm or `pd.plotting.scatter_matrix()`\n",
    "            \n",
    "    - [ ] Check for missing values  (df.isna().sum())\n",
    "        - Can drop rows or colums\n",
    "        - For missing numeric data with median or bin/convert to categorical\n",
    "        - For missing categorical data: make NaN own category OR replace with most common category\n",
    "    - [ ] Check for multicollinearity\n",
    "        - Use seaborn to make correlation matrix plot \n",
    "        - Good rule of thumb is anything over 0.75 corr is high, remove the variable that has the most correl with the largest # of variables\n",
    "    - [ ] Normalize data (may want to do after some exploring)\n",
    "        - Most popular is Z-scoring (but won't fix skew) \n",
    "        - Can log-transform to fix skewed data\n",
    "    \n",
    "    \n",
    "3. **[EXPLORE](#EXPLORE)**\n",
    "    - [ ] Check distributions, outliers, etc**\n",
    "    - [ ] Check scales, ranges (df.describe())\n",
    "    - [ ] Check histograms to get an idea of distributions (df.hist()) and data transformations to perform.\n",
    "        - Can also do kernel density estimates\n",
    "    - [ ] Use scatter plots to check for linearity and possible categorical variables (`df.plot(\"x\",\"y\")`)\n",
    "        - categoricals will look like vertical lines\n",
    "    - [ ] Use `pd.plotting.scatter_matrix(df)` to visualize possible relationships\n",
    "    - [ ] Check for linearity.\n",
    "   \n",
    "   \n",
    "4. **[MODEL](#MODEL)**\n",
    "\n",
    "    - **Fit an initial model:** \n",
    "        - Run an initial model and get results\n",
    "\n",
    "    - **Holdout validation / Train/test split**\n",
    "        - use sklearn `train_test_split`\n",
    "    \n",
    "    \n",
    "5. **[iNTERPRET](#iNTERPRET)**\n",
    "    - **Assessing the model:**\n",
    "        - Assess parameters (slope,intercept)\n",
    "        - Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "        - *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "        - *Whats the impact of collinearity? Can we ignore?*\n",
    "        <br><br>\n",
    "    - **Revise the fitted model**\n",
    "        - Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "        - Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "        - Check for missed non-linearity\n",
    "        \n",
    "       \n",
    "6. **Interpret final model and draw >=3 conclusions and recommendations from dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T18:00:23.504059Z",
     "start_time": "2020-01-29T18:00:23.498461Z"
    }
   },
   "source": [
    "<div style=\"display:block;border-bottom:solid red 3px;padding:1.4em;color:red;font-size:30pt;display:inline-block;line-height:1.5em;\">\n",
    "DELETE THIS CELL AND EVERYTHING ABOVE FROM YOUR FINAL NOTEBOOK\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time:\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n",
    "* Video of 5-min Non-Technical Presentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click to jump to matching Markdown Header.*<br><br>\n",
    " \n",
    "- **[Introduction](#INTRODUCTION)<br>**\n",
    "- **[OBTAIN](#OBTAIN)**<br>\n",
    "- **[SCRUB](#SCRUB)**<br>\n",
    "- **[EXPLORE](#EXPLORE)**<br>\n",
    "- **[MODEL](#MODEL)**<br>\n",
    "- **[iNTERPRET](#iNTERPRET)**<br>\n",
    "- **[Conclusions/Recommendations](#CONCLUSIONS-&-RECOMMENDATIONS)<br>**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "Social media presence is an important part of a modern brand's marketing strategy. But these platforms not only allow brands to broadcast their messages directly to consumers, they also allow consumers to voice their feedback and opinions about the brands candidly, and in a public forum. This translates to a responsibility on one hand, but also an opportunity on the other hand, for companies to listen to and respond to feedback from customers.\n",
    "\n",
    "Many companies use the Net Promoter Score (NPS) as a measure of customer satisfaction and loyalty. However, NPS survey response rates can be low (15%-20% is considered decent) and non-response bias makes the resulting scores unreliable. NPS is also usually just a single question asking how likely a customer is to recommend the company's product to someone else; they may not provide the mechanism for the respondent to give specific feedback about what lead to their answer. Analysis of other channels where customers provide feedback, such as Twitter, could supplement frequently sparse NPS data.\n",
    "\n",
    "If technology could take a first pass on determining the sentiment of tweets, large companies would have a better chance at winnowing constructive, actionable feedback from trolling or irrelevant comments.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What are the business's pain points related to this project?\n",
    "* How did you pick the data analysis question(s) that you did?\n",
    "* Why are these questions important from a business perspective?\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "This data comes from [CrowdFlower](https://data.world/crowdflower/brands-and-product-emotions). It consists of a corpus of tweets which humans were asked to label according to whether they were related to a particular brand or product, and whether a positive, negative, or no emotion was expressed. Tweets about brands or products were labeled with the specific brand or product.\n",
    "***\n",
    "Questions to consider:\n",
    "* Where did the data come from, and how do they relate to the data analysis questions?\n",
    "* What do the data represent? Who is in the sample and what variables are included?\n",
    "* What is the target variable?\n",
    "* What are the properties of the variables you intend to use?\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:04:03.504737Z",
     "start_time": "2021-06-16T00:04:03.308970Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-398-60a5a588e833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "from chardet.universaldetector import UniversalDetector\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer,\\\n",
    "        CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:11.649692Z",
     "start_time": "2021-06-15T23:11:11.245363Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jessicamiles/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:11.746551Z",
     "start_time": "2021-06-15T23:11:11.655002Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:16.529661Z",
     "start_time": "2021-06-15T23:11:11.757774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Windows-1254', 'confidence': 0.43036719349968755, 'language': 'Turkish'}\n"
     ]
    }
   ],
   "source": [
    "# try to detect chatacter encoding of the file\n",
    "detector = UniversalDetector()\n",
    "\n",
    "for line in open('data/judge-1377884607_tweet_product_company.csv', 'r+b').readlines():\n",
    "    #print(line)\n",
    "    detector.feed(line)\n",
    "    if detector.done: break\n",
    "        \n",
    "detector.close()\n",
    "print(detector.result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't especially helpful. I tried cp1254 codec and it was not successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:16.744043Z",
     "start_time": "2021-06-15T23:11:16.542514Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                              @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                           @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4          @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data. Had to switch to latin_1 encoding because encountered errors\n",
    "# with default UTF-8 and windows 1254\n",
    "\n",
    "df = pd.read_csv('data/judge-1377884607_tweet_product_company.csv',\n",
    "                encoding='latin_1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:16.887117Z",
     "start_time": "2021-06-15T23:11:16.754231Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.039376Z",
     "start_time": "2021-06-15T23:11:16.909184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_text emotion_in_tweet_is_directed_at  \\\n",
       "6        NaN                             NaN   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "6                 No emotion toward brand or product  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the one null in the tweet_text column\n",
    "df.loc[df['tweet_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.186072Z",
     "start_time": "2021-06-15T23:11:17.078176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# verified it's blank in the source CSV as well. Going to drop it.\n",
    "df.dropna(subset=['tweet_text'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.317337Z",
     "start_time": "2021-06-15T23:11:17.194347Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_text  9092 non-null   object\n",
      " 1   product     3291 non-null   object\n",
      " 2   emotion     9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# rename the columns to be less verbose\n",
    "col_dict = {'emotion_in_tweet_is_directed_at':'product',\n",
    "           'is_there_an_emotion_directed_at_a_brand_or_product':'emotion'}\n",
    "df.rename(columns=col_dict, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.465688Z",
     "start_time": "2021-06-15T23:11:17.326548Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th>product</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">I can't tell</th>\n",
       "      <th>Apple</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Google product or service</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Negative emotion</th>\n",
       "      <th>Android</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Android App</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Apple product or service</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Google product or service</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad or iPhone App</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">No emotion toward brand or product</th>\n",
       "      <th>Android</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Android App</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Apple product or service</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Google product or service</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad or iPhone App</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>5297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Positive emotion</th>\n",
       "      <th>Android</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Android App</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Apple product or service</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Google product or service</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad</th>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPad or iPhone App</th>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    tweet_text\n",
       "emotion                            product                                    \n",
       "I can't tell                       Apple                                     2\n",
       "                                   Google                                    1\n",
       "                                   Other Google product or service           1\n",
       "                                   iPad                                      4\n",
       "                                   iPhone                                    1\n",
       "                                   NaN                                     147\n",
       "Negative emotion                   Android                                   8\n",
       "                                   Android App                               8\n",
       "                                   Apple                                    95\n",
       "                                   Google                                   68\n",
       "                                   Other Apple product or service            2\n",
       "                                   Other Google product or service          47\n",
       "                                   iPad                                    125\n",
       "                                   iPad or iPhone App                       63\n",
       "                                   iPhone                                  103\n",
       "                                   NaN                                      51\n",
       "No emotion toward brand or product Android                                   1\n",
       "                                   Android App                               1\n",
       "                                   Apple                                    21\n",
       "                                   Google                                   15\n",
       "                                   Other Apple product or service            1\n",
       "                                   Other Google product or service           9\n",
       "                                   iPad                                     24\n",
       "                                   iPad or iPhone App                       10\n",
       "                                   iPhone                                    9\n",
       "                                   NaN                                    5297\n",
       "Positive emotion                   Android                                  69\n",
       "                                   Android App                              72\n",
       "                                   Apple                                   543\n",
       "                                   Google                                  346\n",
       "                                   Other Apple product or service           32\n",
       "                                   Other Google product or service         236\n",
       "                                   iPad                                    793\n",
       "                                   iPad or iPhone App                      397\n",
       "                                   iPhone                                  184\n",
       "                                   NaN                                     306"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the values in the product column? How do they match up to emotions?\n",
    "df.groupby(by=['emotion', 'product'], dropna=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.583188Z",
     "start_time": "2021-06-15T23:11:17.472889Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Thanks to @mention for publishing the news of @mention new medical Apps at the #sxswi conf. blog {link} #sxsw #sxswh',\n",
       "       '\\x89ÛÏ@mention &quot;Apple has opened a pop-up store in Austin so the nerds in town for #SXSW can get their new iPads. {link} #wow',\n",
       "       'Just what America needs. RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw',\n",
       "       'The queue at the Apple Store in Austin is FOUR blocks long. Crazy stuff! #sxsw',\n",
       "       \"Hope it's better than wave RT @mention Buzz is: Google's previewing a social networking platform at #SXSW: {link}\",\n",
       "       'SYD #SXSW crew your iPhone extra juice pods have been procured.',\n",
       "       'Why Barry Diller thinks iPad only content is nuts @mention #SXSW {link}',\n",
       "       'Gave into extreme temptation at #SXSW and bought an iPad 2... #impulse',\n",
       "       'Catch 22\\x89Û_ I mean iPad 2 at #SXSW : {link}',\n",
       "       'Forgot my iPhone for #sxsw. Android only. Knife to a gun fight',\n",
       "       'Kawasaki: key to enchantment = trustworthiness of Zappos + likeability of Richard Branson + product of Apple #sxsw #mccannsxsw #mrmworldwide',\n",
       "       'Google no lanzara ningun producto en South by SouthWest #sxsw 2011 {link}',\n",
       "       'Comprando mi iPad 2 en el #SXSW (@mention Apple Store, SXSW w/ 62 others) {link}',\n",
       "       'I can now say that Google got me drunk #sxsw #h4ckers',\n",
       "       'ipad is a slow resting heartrate  #tapworthy #sxsw #gsdm about leisure vs quick results on iphone',\n",
       "       'Walked by the mobile Apple store in austin.  Line was insane. #sxsw',\n",
       "       'This Waze vs Google discussion is one of the best I have seen at #sxsw. We need more competitors going head to head here.',\n",
       "       'Wow folks, make sure that iPhone ringer is turned ALL the way up when u have to be up pre-sunrise for a flight. #internalalarmclockFTW #sxsw',\n",
       "       \"Let's see: Google announcing Circles, Obama in Austin, #SXSW donates proceeds to Japan. Ho hum\",\n",
       "       \"@mention :) Maybe not *entirely* HD (Flip? iPhone? Other XL2 footage?) -- but certainly your concerts at #SXSW. It's gonna be grand.\",\n",
       "       '@mention @mention @mention #Platformer CI di venues #SXSW pake 3 app 4sq API,D cnth : Tweetdeck etc (via : iPhone, Android, iPad and PC)',\n",
       "       \"Google's @mention &quot;credit card cos. know with 98% accuracy 2 yrs before that you're going to get divorced&quot; {link} #sxsw\",\n",
       "       '@mention @mention be sure to check out the @mention jukebox app running party music for #SXSW. With the @mention API.  {link}',\n",
       "       'Hijacked @mention iPhone since mine is DOA. Muahahahahhaahahaa. #SXSW partay time. Thx @mention for dinner',\n",
       "       'Apple is &quot;the classiest, fascist company in America,&quot; says @mention #sxsw',\n",
       "       \"I'd take #sxsw hashtags over scheen, ipad/ipad2, tv or sports tweets any day, but for those needing a filter\\x89Û_ {link}\",\n",
       "       'The iPad 2 is the also a cartoonishly large digital camera. #SXSW #CStejas {link}',\n",
       "       'O no,not again {link} Google Circles Juwan Howard #sxsw',\n",
       "       \"I just realized my iPhone's gonna go nuts with Foursquare and Gowalla updates. #SXSW\",\n",
       "       \"At the Team Android party. Can't find it on Gowalla or Foursquare, so um, there you go. #sxsw\",\n",
       "       \"Just buy an iPad 2 at #SXSW? Give it the finger. Better yet, give it four of 'em :: {link}\",\n",
       "       'Vai comeÌ¤ar a palestra do  @mention ex-chief evangelist of Apple #sxsw',\n",
       "       'Man gets arrested at #sxsw for not having an iPhone.  {link}',\n",
       "       'iPhone crashed in front of #sxsw Apple pop-up. #bestworstthingever',\n",
       "       'Did... what my mom might call The Big at #SXSW. Power plant, CNN, Google, and offchain set by Trombone Shorty at PBS. So sad missed Rye Rey',\n",
       "       'William Patry, google, says most authors dont care about copyright, they care about income. #sxsw but what models?',\n",
       "       'Any blackberry apps for #sxsw ?? Pls let @mention and I know...cheers...will have iphone too...:-)',\n",
       "       'ipadi alacagimiz yer belli oldu:  Apple to Open Pop-Up Shop at Austin #SXSW {link} via @mention @mention',\n",
       "       'Saw a bunch of security guards playing with iPads at the apple store after hours last night #sxsw {link}',\n",
       "       'My #agnerd confession, using laptop, iPad and blackberry to follow #SXSW from afar to see #agchat rock it',\n",
       "       \"I'm bummed that I missed the Team Android party at #SXSW... Oh well, CTIA is right around the corner... Boom, roasted...\",\n",
       "       'Next up: designing interfaces for iPad. Or should I hit up &quot;Your Brand is Obsolete&quot;? #SXSW',\n",
       "       'Thank goodness for these two hour breaks where I have turn off my iPhone, or my battery would be TOAST!  #sxsw',\n",
       "       'Temp store #sxsw  @mention Apple Store, SXSW {link}',\n",
       "       'I wish the apple store employees cheering for all the people in line at the pop up apple store would cheer me on while I do timesheets #SXSW',\n",
       "       \"I won't be at #sxsw and I won't be in line to buy iPad 2.0 tomorrow. #notwinning.\",\n",
       "       'Looks like the line for the Apple pop-up store on Congress Ave is already down to the end of the block..  #SXSW #SteveJobsWins',\n",
       "       \"Good place to test it. Will it be edgy enough? @mention Q2 - Google's check in offers? Testing at #sxsw {link} #smccolumbus\",\n",
       "       \"Hope there's time left for Poked Liked and retweeted and Google love story (social vs search). #sxsw\",\n",
       "       \"#SXSW haven't trend this time because of the tsunami..the iPad 2 did though.\",\n",
       "       '#UXdes @mention is glad there are no standard #iPad navigation tools. She might be the only one! #SXSW',\n",
       "       '#sxsw: @mention We think we control our identities on Facebook, but as Google becomes an AI our profile will be built of what we do',\n",
       "       \"#SXSW. Peep the awesome product video - @mention can't compete with these games. - {link} - CC @mention  @mention\",\n",
       "       \"Google doesn't place any value on your domain extension. They are all equal. #SXSW #qagb\",\n",
       "       'Reports of @mention introducing a new social media platform at #SXSW were premature, but hopefully not overly optimistic {link}',\n",
       "       \"Google's Facebook-killer &quot;Circles&quot; to be unveiled today at #SXSW? {link}\",\n",
       "       '@mention FourSquare is pushing their 3.0 iPhone/Android app heavily here at #sxsw. Wish they gave your webOS client equal billing.',\n",
       "       'Liveblog from #SXSW: Can indie #iPhone game development survive? {link} #games',\n",
       "       'is walking around #SXSW while staring down at my iPhone 4... Just like everyone else.',\n",
       "       'Google might launching a social network called Circles at #SXSW ... of course {link}',\n",
       "       '&quot;Google products need to be condensed&quot;,  #Merissa #Mayor at #SXSW Conference 2011 {link}',\n",
       "       '#Apple, #Google, #Intel and Others Go Gaga for the Go Game | Fast Company {link} #SXSW #SocialMedia #createyourownadventure',\n",
       "       \"Bet on a GoogleBuzz-like #fail. People don't care about privacy, else they'd quitted FB/TW already RT @mention Google Circles will be __ #sxsw\",\n",
       "       'I am neither at #SXSW nor buying an iPad 2 today. I feel like my geek cred is basically gone.',\n",
       "       'funny! iphone correction? RT @mention Dashing off to learn a thing or two about longhorn journalism #SXSW',\n",
       "       \"Diller: Why would you do product only for the iPad or any one form factor in today's multichannel, multi platform world? #SXSW #KetchSX\",\n",
       "       \"+1 \\x89ÛÏ@mention +1 RT @mention Petricone says Google TV is just a browser. I don't think that's correct. #SXSW\\x89Û\\x9d\",\n",
       "       '@mention is biyt.ly for email, like google voice for email #loveit #sxsw #startupbus',\n",
       "       \"the panelist from Texas Observer called the iPad a lean back device #SXSW #in #newsapp #i'mconfused\",\n",
       "       'I agree with @mention on their @mention concerns, but your #sxsw #microformats panelist is just condescending and rude.',\n",
       "       'I would give my Apple stock to be more like @mention {link} #SXSW',\n",
       "       'need to give my iPhone &amp; liver a rest. #SXSW',\n",
       "       'I feel like my iPhone: Always on, always doing something, running out of battery fast. #sxsw',\n",
       "       'LOL. #Apple erects temporary Apple Store in #Austin for #SXSW to sell #iPad 2. {link}',\n",
       "       'Line a mile long outside. Lucky to get in just to sit on the floor -Your Mom Has An iPad. I miss the old days at #sxsw before 40% + growth!',\n",
       "       'Barry Diller interview at #SXSW was pretty high level. Does not understand the Daily on iPad. All company valuations are high.',\n",
       "       'Hi, if came out here for #sxsw and in line at the temp apple store to buy an ipad2 for the fuck home. #douchebloggers',\n",
       "       'Nuts.  \\x89ÛÏ@mention @mention (via @mention #sxsw ipad store sold out of everything except 64gig wifi only white\\x89Û\\x9d',\n",
       "       'DANG RT @mention Confirmed! Apple store 2 week popup in Austin for #SXSW {link} (via @mention who gave us no credit! )',\n",
       "       'Do the Humpty hump!  Google ACLU Party like its 1986! #SXSW',\n",
       "       'This iphone game presentation is being delivered on a windows laptop.  #amusing #sxsw',\n",
       "       'another one? holy social fragmentation&gt;Google to Launch New Social Network Called Circles, Possibly 2day at #sxsw {link} @mention',\n",
       "       \"Ok. Someone's trying to tell me something: For the 2nd day in a row I got to the #sxsw Apple store right as it closed.\",\n",
       "       'Google/Bing search smackdown panel is in a giant room with not enough chairs. Hope you have a search for &quot;floor-sitting!&quot; #SXSW',\n",
       "       \"Always wanted this! RT @mention Sound of My Voice was shot exploiting Apple &amp; Best Buy's 14-day return policy on iMacs. Brilliant. #sxsw\",\n",
       "       'It is also limited in its abilities. Its a balance. RT @mention @mention An iPad is cheaper than most laptops. #newsapps #sxsw',\n",
       "       'Anyone who was going to buy a new iPad should donate to #Japan #tsunami victims instead. #sxsw',\n",
       "       \"At home today. @mention at #sxsw: &quot;apple comes up with cool technology no one's ever heard of because they don't go to conferences&quot;\",\n",
       "       'The hive of innovation but yet every booth at the #SXSW trade show had the exact same promotional idea: iPad 2 Raffle!',\n",
       "       \"Yikes. Google is launching 'Circles' today at #sxsw? {link}\",\n",
       "       'RT @mention @mention to Launch Social Network Called Circles, Possibly Today {link} #sxsw via: @mention - This should be interesting ^ JL',\n",
       "       \"The session #designingforkids is changing my mind about my future kid's relationship with the iPhone. #sapient #sxsw\",\n",
       "       \"RT @mention #sxsw @mention #devops: @mention &quot;The Internets is Mean/Our Systems Are Complex; go Google 'How complex systems fail by doctor&quot;\",\n",
       "       'RT @mention #sxsw: @mention We think we control our identities on Facebook, but as Google becomes an AI our profile will be built of what we do',\n",
       "       'standing on a long line surrounded by unemployed techies from brooklyn!  am i at #sxsw or at the apple store on 5th ave waiting for ipad?!',\n",
       "       'RT @mention another one? holy social fragmentation&gt;Google to Launch New Social Network Called Circles, Possibly 2day at #sxsw {link} @mention',\n",
       "       'RT @mention Apple, Google, Intel ... Go Gaga for The Go Game by @mention @mention  {link} (cc @mention @iangogame) #LI #SXSW',\n",
       "       \"RT @mention Best thing I've heard this weekend at #SXSW &quot;I gave my iPad 2 money to #Japan relief. I don't ne... {link}\",\n",
       "       'RT @mention Demo of Google Hotpot at #bettersearch panel: still pull search, but personalized. Not yet serendipitous? #SXSW',\n",
       "       \"RT @mention Design for iPad is like design 101. Will someone give a talk and assume that we didn't all ditch our prev experience #sxsw\",\n",
       "       'RT @mention Gary Vaynerchuck lÌ_gger ner winelibrary.tv och slÌ_pper i stÌ_llet Iphone-appen Daily Grape. #thankyoueconomy #sxsw #swesxsw',\n",
       "       'RT @mention Google is announcing a social network &quot;Circles&quot; (via #SXSW tweets). Interesting. Myopia will cause Buzz jokes. But...',\n",
       "       'TR @mention Google (tries again) to launch a new social network called Circles: {link} #sxsw {link}',\n",
       "       'RT @mention Has spontaniety in life been replaced by technology? When your iPhone battery dies you go home. Great ? At #busy #sxsw',\n",
       "       'RT @mention Hmm....only 9? #SXSW right-brain #mwrc11 left-brain?? :) RT @mention @mention at #SXSW 9 out of 10 attendees have Mac or iPad',\n",
       "       'RT @mention my biggest mistake since South By Southwest last year? writin a book bout iPhone photography instead of makin a photography iPhone app #SXSW',\n",
       "       'RT @mention Official #SXSW App \\x89Û÷SXSW GO\\x89Ûª bit.ly/hmiiGa #android #iphone #ipad',\n",
       "       'RT @mention Reactions to Google Circles news so far range from &quot;not again&quot; to &quot;please rescue me from the Facebook.&quot; #sxsw',\n",
       "       'RT @mention RT @mention @mention @mention Austin street closures during SXSW in Google Map form: {link} #sxsw #austin',\n",
       "       'RT @mention Selfishness as seen through brands: Mac versus Apple. Apple wins: they are masters at being self-referential  #sxsw',\n",
       "       \"RT @mention So many Google products. isn't it time to  transition them down the chain and into  features? But features of what product? #SXSW\",\n",
       "       'OH @mention the Apple Pop-Up Store: &quot;Oh... you have the old one.&quot; #crazytimes #sxsw',\n",
       "       'RT @mention The iPad 1 is so March 11, 2011 4:59PM PST. #sxsw',\n",
       "       'RT @mention Well damn, Apple setting up a &quot;pop-up&quot; shop at #SXSW {link}',\n",
       "       'RT @mention Win an #OpenBeta6 iPad @mention this #sxsw panel {link}  today @mention 11! #usguys cc @mention  #DgtlTribe #sxswbuffalo',\n",
       "       'I think google circles was an effect of crop `circle` #SXSW #randomly',\n",
       "       'How can google load those maps so fast, yet I can barely post a tweet haha #sxsw',\n",
       "       'Finally got my #SXSW schedule on my #google calendar. #coudbeeasier',\n",
       "       \"Killer thought from @mention - if you are not paying for a service, it's probably you that is being sold (ref Google, TV ads etc)#sxsw #psfk\",\n",
       "       'Google should put those engineers formerly behind real estate listings into renewing the Google Checkout project. #SXSW',\n",
       "       'Checking out Mistakes I Made Building Netflix for the iPhone at #SXSW.\\n{link} #netflixiphone',\n",
       "       'curious how iPad 2 sales went in Austin, TX where a lot of potential iPad 2 buyers are attending #SXSW',\n",
       "       'Anyone know status of iPad 2s in Austin pop-up store? Sold out? Getting more? #ipad2 #sxsw',\n",
       "       \"The new iPad is like fight club, you don't talk about fight club   #SXSW\",\n",
       "       \"@mention Picked up mophie juice boost pack for iPhone. This chick -and wknd- calls for ample juice #SXSW // 'hight-tech energy drink'\",\n",
       "       'Original products for 1 device is nuts. #sxsw. Eg the iPad',\n",
       "       'Google Maps car just drove by. Might leave a distorted view of Austin. #sxsw',\n",
       "       'Google maps used to provide common reference points and printed for fast paced on the ground reactions #arabspring #SXSW',\n",
       "       'Google Circles - looking forward to this. sadly no launch at #SXSW',\n",
       "       \"At the airport playing my fav game:  &quot;Are You Going to #SXSW?&quot; Wearing denim on denim? You're going.  Charging 3+ Apple products? You too.\",\n",
       "       '@mention RWW: Google Circles will be ______    #sxsw {link}',\n",
       "       \"#sxsw it's absolutely hysterical watching people take photos w an iPad!!\",\n",
       "       'Regardless of keyword - Google thinks local. #mobilesearch #SXSW #SXSWi',\n",
       "       \"How to design for baby boomers: DON'T. John McRee on #iPad design #sxsw #yourmom\",\n",
       "       'Line for Source Code is even longer than for iPad 2. Take that, Apple. #sxsw',\n",
       "       'After #SXSW I will never again take a fully charged IPhone for granted; 24/7 pics edit tweet 4square apps =zap!',\n",
       "       'Sitting at a bar listening to music w 3 ppl who r all nose down on iPhone. Waitress looks confused. #sxsw',\n",
       "       'Entrapment. Layer upon layer RT: @mention Google Circles will be ______ #sxsw&quot;',\n",
       "       \"I'll bet there's a lot of nerds at #SXSW using the #iPhone Light Saber app in barroom brawls instead of their fists.\",\n",
       "       'I really think that most of the iPad 2 stock went down to #SXSW.',\n",
       "       'Apple setting up a temporary store at #SXSW to sell the #iPad2. Crazy? Brilliant? Convenient? {link}  #apple #news #SXSWi',\n",
       "       \"This @mention article about #SXSW is so good I'm linking to it on an iPhone on a train, which is the opposite of easy: {link}\",\n",
       "       \"Like @mention I've now seen most of Austin in Google Streetview checking out apartments for #sxsw. Austin is not easy on the click.\",\n",
       "       '&quot;multiple approaches to monetization&quot; re: iPhone game dev &quot;but ads would cheapen our product&quot; ok, good luck with that #sxsw',\n",
       "       'iPhone battery maintenance is a fine art at #sxsw',\n",
       "       'Google actually does have an official death policy. One of only a few. via @mention #digitaldeath #sxsw',\n",
       "       '#SocialNetworks: #Google noch heute mit #Circles? #Facebook-Konkurrent! {link} via @mention und {link} #SXSW',\n",
       "       'In case our rabbits forgot theirs at home! Apple Opening Pop-Up Store In Austin For #SXSW {link}',\n",
       "       \"RT never use mine on the go RT @mention &quot;You're probably using your iPad on the go.&quot; #disagree #SXSW #uxdes\",\n",
       "       'Geez #sxsw people are eating this up. Another line outside the apple store for iPad 2 in austin {link}',\n",
       "       'From #SXSW: @mention says @mention playing with NFC for next gen devices. Nexus S now, iPhone 5 next?',\n",
       "       \"It's funny watching a room full of people hold their iPad in the air to take a photo. Like a room full of tablets staring you down. #SXSW\",\n",
       "       '@mention yeah, we have @mention , Google has nothing on us :) #SXSW',\n",
       "       '@mention Yes, the Google presentation was not exactly what I was expecting. #sxsw',\n",
       "       '&quot;Do you know what Apple is really good at? Making you feel bad about your Xmas present!&quot; - Seth Meyers on iPad2 #sxsw #doyoureallyneedthat?',\n",
       "       'How much you want to bet Apple is disproportionately stocking the #SXSW pop-up store with iPad 2? The influencer/hipsters thank you'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get a sample of \"I can't tell\"\n",
    "df[df['emotion']==\"I can't tell\"]['tweet_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to put all of the tweets through tokenization and preprocessing. I will train my model on the tweets which are labeled positive or negative emotions, but I might want to use the \"no emotion\" and \"I can't tell\" labeled tweets to help confirm the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* Were there variables you dropped or created?\n",
    "* How did you address missing values or outliers?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.702993Z",
     "start_time": "2021-06-15T23:11:17.599038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.\n",
       "1    @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\n",
       "2                                                                @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.\n",
       "3                                                             @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw\n",
       "4            @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the tweet text, so I can keep the original pristine\n",
    "df['cleaned'] = df['tweet_text']\n",
    "df['cleaned'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text as documents\n",
    "\n",
    "Before splitting into words, I'm going to do some text cleaning on the whole documents.\n",
    "\n",
    "I noticed when taking an initial look at the corpus that I have some existing placeholders which were probably added when anonymizing this dataset for the public:\n",
    "- @mention\n",
    "- {link}\n",
    "\n",
    "I'm going to remove the links because as words they won't be especially helpful, but I do want to keep track of tweets that had links, since that might be an interesting feature to examine.\n",
    "\n",
    "Most of the @mentions appear to be placeholders, but not all are, some are the original handles. I think it's worth capturing the mentions in a column as well as hashtags, so these can be analyzed separately. I'll do the preprocessing in a specific order, so as to replace some of these and capture the information I want before replacing the rest. \n",
    "\n",
    "I also have some characters with encoding that I can't replicate; they could be emojis but in some instances they look to be unicode apostrophes and quotation marks. I'll replace these, since I can't find any way to easily get them encoded correctly.\n",
    "\n",
    "Finally, I did also notice that some people put Twitter abbreviations such as \"RT\" for retweet. I may engineer a feature indicating whether a tweet is a retweet, and remove that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:17.834433Z",
     "start_time": "2021-06-15T23:11:17.709351Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_text, product, emotion, cleaned]\n",
       "Index: []"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for literal (unescaped) open or closing HTML tags\n",
    "df[df['tweet_text'].str.contains(\"[<>]\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no \"<>\" characters in any of the tweets, I will not add anything to remove HTML tags from the text when I clean it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:18.102123Z",
     "start_time": "2021-06-15T23:11:17.906328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&amp;gt;http://bit.ly/aXZwxB</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&amp;gt;http://bit.ly/aXZwxB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Surprise! Apple has opened a pop-up store in Austin so that the nerds in town for #SXSW can get their new iPads. http:/ {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Surprise! Apple has opened a pop-up store in Austin so that the nerds in town for #SXSW can get their new iPads. http:/ {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>A special Apple store: opening at 6th and Congress for SXSW &amp;amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>A special Apple store: opening at 6th and Congress for SXSW &amp;amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>Check out the @mention Route {link} ; RSVP here -&amp;gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Check out the @mention Route {link} ; RSVP here -&amp;gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>Pics from the #apple #ipad2 line at #SXSW #fb  {link} {link} http://t.co/26SVO3m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Pics from the #apple #ipad2 line at #SXSW #fb  {link} {link} http://t.co/26SVO3m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>Apple set to open popup shop in core of SXSW action {link} #sxsw #app... {link} http://bit.ly/bvHD5s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Apple set to open popup shop in core of SXSW action {link} #sxsw #app... {link} http://bit.ly/bvHD5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>I'll pay $681.00 for a New, Unopened iPad 2 16GB with 3G for Verizon - Black. Visit www.Zaarly.com to claim the cash. #willpay #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>I'll pay $681.00 for a New, Unopened iPad 2 16GB with 3G for Verizon - Black. Visit www.Zaarly.com to claim the cash. #willpay #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>Off to Google party with @mention then @mention @mention @mention at www.getdown.com #msusxsw #sxsw Tweet me if you're there! (@jeremie)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Off to Google party with @mention then @mention @mention @mention at www.getdown.com #msusxsw #sxsw Tweet me if you're there! (@jeremie)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>RT The coolest iPhone 4 &amp;amp; iPad cases at #Sxsw, check them out here at #fastcompanygrill #zazzlesxsw #sxswi  http... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT The coolest iPhone 4 &amp;amp; iPad cases at #Sxsw, check them out here at #fastcompanygrill #zazzlesxsw #sxswi  http... {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>RT @mention @mention hey Rudy, are Belgiums and Dutch taking over #sxsw? We launched www.skylines.net and {link} today</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT @mention @mention hey Rudy, are Belgiums and Dutch taking over #sxsw? We launched www.skylines.net and {link} today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370</th>\n",
       "      <td>RT @mention A special Apple store: opening at 6th and Congress for SXSW &amp;amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT @mention A special Apple store: opening at 6th and Congress for SXSW &amp;amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5488</th>\n",
       "      <td>RT @mention Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT @mention Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>RT @mention At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>RT @mention At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>RT @mention Check out the @mention Route {link} ; RSVP here -&amp;gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT @mention Check out the @mention Route {link} ; RSVP here -&amp;gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>RT @mention Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT @mention Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>RT @mention Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>RT @mention Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>RT @mention Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>RT @mention Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>RT @mention We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>RT @mention We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>Saw a company today ready to launch, sounds a lot like Google Circles, but with actual personal privacy www.mycube.com #sxsw</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Saw a company today ready to launch, sounds a lot like Google Circles, but with actual personal privacy www.mycube.com #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7721</th>\n",
       "      <td>miami horror, tacos and bloody marys. i'm there. https://sites.google.com/site/frontgatesxsw11/ #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>miami horror, tacos and bloody marys. i'm there. https://sites.google.com/site/frontgatesxsw11/ #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>Per this rumor, Google may preview its big social strategy at an '80s-themed costume party at #SXSW. Yep. http:/... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Per this rumor, Google may preview its big social strategy at an '80s-themed costume party at #SXSW. Yep. http:/... {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047</th>\n",
       "      <td>Adloopz: Social Media Advertising done the easy way. Visit www.adloopz.com  #SXSW #sxswi #ipad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Adloopz: Social Media Advertising done the easy way. Visit www.adloopz.com  #SXSW #sxswi #ipad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>@mention Sweet 8-bit pic. Are you an artist? www.zaggle.org is having an #art contest for our #iPhone app Check it out We'll be at #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>@mention Sweet 8-bit pic. Are you an artist? www.zaggle.org is having an #art contest for our #iPhone app Check it out We'll be at #SXSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8849</th>\n",
       "      <td>We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win)</td>\n",
       "      <td>iPad</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 tweet_text  \\\n",
       "5              @teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd   \n",
       "8                         Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB   \n",
       "11                        Find &amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.   \n",
       "12                    Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.   \n",
       "13           Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&gt;http://bit.ly/aXZwxB   \n",
       "14                                                                                        Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l   \n",
       "15                                                                       haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw   \n",
       "16                                                             Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw   \n",
       "19                                   Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV   \n",
       "23                                                           Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7   \n",
       "26                                              RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)   \n",
       "28              The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird   \n",
       "30                                      Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)   \n",
       "31                   You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram   \n",
       "272                          Surprise! Apple has opened a pop-up store in Austin so that the nerds in town for #SXSW can get their new iPads. http:/ {link}   \n",
       "293               A special Apple store: opening at 6th and Congress for SXSW &amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb   \n",
       "1133                              Check out the @mention Route {link} ; RSVP here -&gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw   \n",
       "1139                                                                       Pics from the #apple #ipad2 line at #SXSW #fb  {link} {link} http://t.co/26SVO3m   \n",
       "1241                                                   Apple set to open popup shop in core of SXSW action {link} #sxsw #app... {link} http://bit.ly/bvHD5s   \n",
       "1758                   I'll pay $681.00 for a New, Unopened iPad 2 16GB with 3G for Verizon - Black. Visit www.Zaarly.com to claim the cash. #willpay #sxsw   \n",
       "2736                                     Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music   \n",
       "3511                                                             At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco   \n",
       "4962               Off to Google party with @mention then @mention @mention @mention at www.getdown.com #msusxsw #sxsw Tweet me if you're there! (@jeremie)   \n",
       "5002                         RT The coolest iPhone 4 &amp; iPad cases at #Sxsw, check them out here at #fastcompanygrill #zazzlesxsw #sxswi  http... {link}   \n",
       "5130                                 RT @mention @mention hey Rudy, are Belgiums and Dutch taking over #sxsw? We launched www.skylines.net and {link} today   \n",
       "5370  RT @mention A special Apple store: opening at 6th and Congress for SXSW &amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb   \n",
       "5488                                               RT @mention Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com   \n",
       "5521                                                 RT @mention At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco   \n",
       "5608                  RT @mention Check out the @mention Route {link} ; RSVP here -&gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw   \n",
       "5729                                   RT @mention Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp   \n",
       "5753                         RT @mention Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music   \n",
       "6478                           RT @mention Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect   \n",
       "6879                RT @mention We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win   \n",
       "7350                           Saw a company today ready to launch, sounds a lot like Google Circles, but with actual personal privacy www.mycube.com #sxsw   \n",
       "7521                                               Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp   \n",
       "7721                                                  miami horror, tacos and bloody marys. i'm there. https://sites.google.com/site/frontgatesxsw11/ #sxsw   \n",
       "7802                             Per this rumor, Google may preview its big social strategy at an '80s-themed costume party at #SXSW. Yep. http:/... {link}   \n",
       "8047                                                         Adloopz: Social Media Advertising done the easy way. Visit www.adloopz.com  #SXSW #sxswi #ipad   \n",
       "8141               @mention Sweet 8-bit pic. Are you an artist? www.zaggle.org is having an #art contest for our #iPhone app Check it out We'll be at #SXSW   \n",
       "8201                                                           Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com   \n",
       "8250                                       Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect   \n",
       "8849                           We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win)   \n",
       "\n",
       "                              product                             emotion  \\\n",
       "5                                 NaN  No emotion toward brand or product   \n",
       "8                  iPad or iPhone App                    Positive emotion   \n",
       "11                        Android App                    Positive emotion   \n",
       "12                        Android App                    Positive emotion   \n",
       "13    Other Google product or service                    Positive emotion   \n",
       "14                 iPad or iPhone App                    Positive emotion   \n",
       "15                 iPad or iPhone App                    Positive emotion   \n",
       "16                                NaN  No emotion toward brand or product   \n",
       "19                 iPad or iPhone App                    Positive emotion   \n",
       "23                 iPad or iPhone App                    Positive emotion   \n",
       "26                 iPad or iPhone App                    Positive emotion   \n",
       "28                 iPad or iPhone App                    Positive emotion   \n",
       "30                 iPad or iPhone App                    Positive emotion   \n",
       "31                 iPad or iPhone App                    Positive emotion   \n",
       "272                               NaN  No emotion toward brand or product   \n",
       "293                               NaN  No emotion toward brand or product   \n",
       "1133                              NaN  No emotion toward brand or product   \n",
       "1139                              NaN  No emotion toward brand or product   \n",
       "1241                              NaN  No emotion toward brand or product   \n",
       "1758                              NaN  No emotion toward brand or product   \n",
       "2736                              NaN  No emotion toward brand or product   \n",
       "3511                              NaN  No emotion toward brand or product   \n",
       "4962                              NaN  No emotion toward brand or product   \n",
       "5002                              NaN  No emotion toward brand or product   \n",
       "5130                              NaN  No emotion toward brand or product   \n",
       "5370                              NaN  No emotion toward brand or product   \n",
       "5488                              NaN  No emotion toward brand or product   \n",
       "5521                             iPad                    Positive emotion   \n",
       "5608                              NaN  No emotion toward brand or product   \n",
       "5729                              NaN  No emotion toward brand or product   \n",
       "5753                              NaN  No emotion toward brand or product   \n",
       "6478                      Android App                    Positive emotion   \n",
       "6879                             iPad                    Positive emotion   \n",
       "7350  Other Google product or service  No emotion toward brand or product   \n",
       "7521               iPad or iPhone App  No emotion toward brand or product   \n",
       "7721                              NaN  No emotion toward brand or product   \n",
       "7802                              NaN  No emotion toward brand or product   \n",
       "8047                              NaN  No emotion toward brand or product   \n",
       "8141                              NaN  No emotion toward brand or product   \n",
       "8201                              NaN  No emotion toward brand or product   \n",
       "8250                              NaN                    Positive emotion   \n",
       "8849                             iPad  No emotion toward brand or product   \n",
       "\n",
       "                                                                                                                                                    cleaned  \n",
       "5              @teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd  \n",
       "8                         Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB  \n",
       "11                        Find &amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.  \n",
       "12                    Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.  \n",
       "13           Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&gt;http://bit.ly/aXZwxB  \n",
       "14                                                                                        Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l  \n",
       "15                                                                       haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw  \n",
       "16                                                             Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw  \n",
       "19                                   Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV  \n",
       "23                                                           Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7  \n",
       "26                                              RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)  \n",
       "28              The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird  \n",
       "30                                      Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)  \n",
       "31                   You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram  \n",
       "272                          Surprise! Apple has opened a pop-up store in Austin so that the nerds in town for #SXSW can get their new iPads. http:/ {link}  \n",
       "293               A special Apple store: opening at 6th and Congress for SXSW &amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb  \n",
       "1133                              Check out the @mention Route {link} ; RSVP here -&gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw  \n",
       "1139                                                                       Pics from the #apple #ipad2 line at #SXSW #fb  {link} {link} http://t.co/26SVO3m  \n",
       "1241                                                   Apple set to open popup shop in core of SXSW action {link} #sxsw #app... {link} http://bit.ly/bvHD5s  \n",
       "1758                   I'll pay $681.00 for a New, Unopened iPad 2 16GB with 3G for Verizon - Black. Visit www.Zaarly.com to claim the cash. #willpay #sxsw  \n",
       "2736                                     Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music  \n",
       "3511                                                             At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco  \n",
       "4962               Off to Google party with @mention then @mention @mention @mention at www.getdown.com #msusxsw #sxsw Tweet me if you're there! (@jeremie)  \n",
       "5002                         RT The coolest iPhone 4 &amp; iPad cases at #Sxsw, check them out here at #fastcompanygrill #zazzlesxsw #sxswi  http... {link}  \n",
       "5130                                 RT @mention @mention hey Rudy, are Belgiums and Dutch taking over #sxsw? We launched www.skylines.net and {link} today  \n",
       "5370  RT @mention A special Apple store: opening at 6th and Congress for SXSW &amp; ipad 2 launch. www.apple.com/retail/thedomain/  #Apple #iPad2 #sxsw #fb  \n",
       "5488                                               RT @mention Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com  \n",
       "5521                                                 RT @mention At #tweethouse watching #ipad dj @mention rock out at #sxsw! Check out www.rana.co! #dotco  \n",
       "5608                  RT @mention Check out the @mention Route {link} ; RSVP here -&gt; https://www.facebook.com/event.php?eid=141164002609303 #sxswi #sxsw  \n",
       "5729                                   RT @mention Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp  \n",
       "5753                         RT @mention Front Gate Tickets Present The Morning After Party 3/18 https://sites.google.com/site/frontgatesxsw11/ #SXSW Music  \n",
       "6478                           RT @mention Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect  \n",
       "6879                RT @mention We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win  \n",
       "7350                           Saw a company today ready to launch, sounds a lot like Google Circles, but with actual personal privacy www.mycube.com #sxsw  \n",
       "7521                                               Follow our #SXSW coverage at {link} on mobile at {link} or with our iPhone app http://bit.ly/guardianapp  \n",
       "7721                                                  miami horror, tacos and bloody marys. i'm there. https://sites.google.com/site/frontgatesxsw11/ #sxsw  \n",
       "7802                             Per this rumor, Google may preview its big social strategy at an '80s-themed costume party at #SXSW. Yep. http:/... {link}  \n",
       "8047                                                         Adloopz: Social Media Advertising done the easy way. Visit www.adloopz.com  #SXSW #sxswi #ipad  \n",
       "8141               @mention Sweet 8-bit pic. Are you an artist? www.zaggle.org is having an #art contest for our #iPhone app Check it out We'll be at #SXSW  \n",
       "8201                                                           Are you at #sxsw? Check out #Tokii in the the Maple Leaf Digital Lounge {link} www.tokii.com  \n",
       "8250                                       Retrollect is now also in Android Market! #SxSW https://market.android.com/details?id=com.borderstylo.retrollect  \n",
       "8849                           We can't wait to give an iPad to someone at #sxsw. Want in? Just head to www.pep.jobs/upc to enter. (must be present to win)  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for links or URLs\n",
    "df[df['tweet_text'].str.contains(\"http[^ ]+|www\\.[^ ]+\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I definitely do have URLs, which I will remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:18.333065Z",
     "start_time": "2021-06-15T23:11:18.117101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>@mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW</td>\n",
       "      <td>Google</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>@mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android: Whether youÛªre getting friend... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android: Whether youÛªre getting friend... {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>#IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>umm that would be @mention ÛÏ@mention I keep winning shit! Thanks @mention for the killer iPad case. #sxswÛ</td>\n",
       "      <td>Other Apple product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>umm that would be @mention ÛÏ@mention I keep winning shit! Thanks @mention for the killer iPad case. #sxswÛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>FestivalExplorer iPhone App Finally Solves SXSW {link} #music #musica #musiek #musique #musik #app #sxsw #Ù_¾¬â #Ù_¾´_ #Î¥É</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>FestivalExplorer iPhone App Finally Solves SXSW {link} #music #musica #musiek #musique #musik #app #sxsw #Ù_¾¬â #Ù_¾´_ #Î¥É</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>Group #Texting War Heats Up: Fast Society Launches New Android App, Updates iPhone App: #SXSWÛ_ {link}</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Group #Texting War Heats Up: Fast Society Launches New Android App, Updates iPhone App: #SXSWÛ_ {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>In case my fairy god mother = reading mail; my ÌÙ±G wish this week is 2 go 2 #sxsw Ï for the #Android ÏÎ Dev Ïà Meetup. @mention Hilton, Sat....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>In case my fairy god mother = reading mail; my ÌÙ±G wish this week is 2 go 2 #sxsw Ï for the #Android ÏÎ Dev Ïà Meetup. @mention Hilton, Sat....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 tweet_text  \\\n",
       "38                                  @mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW   \n",
       "41                         HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android: Whether youÛªre getting friend... {link}   \n",
       "42                        Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!   \n",
       "45                                             #IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW   \n",
       "46                                                              Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}   \n",
       "...                                                                                                                                                     ...   \n",
       "8925                                         umm that would be @mention ÛÏ@mention I keep winning shit! Thanks @mention for the killer iPad case. #sxswÛ   \n",
       "8945                       FestivalExplorer iPhone App Finally Solves SXSW {link} #music #musica #musiek #musique #musik #app #sxsw #Ù_¾¬â #Ù_¾´_ #Î¥É   \n",
       "8963                                                Group #Texting War Heats Up: Fast Society Launches New Android App, Updates iPhone App: #SXSWÛ_ {link}   \n",
       "8982  In case my fairy god mother = reading mail; my ÌÙ±G wish this week is 2 go 2 #sxsw Ï for the #Android ÏÎ Dev Ïà Meetup. @mention Hilton, Sat....   \n",
       "9092                                               Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                             product                             emotion  \\\n",
       "38                            Google                    Negative emotion   \n",
       "41                               NaN  No emotion toward brand or product   \n",
       "42                               NaN  No emotion toward brand or product   \n",
       "45                iPad or iPhone App                    Positive emotion   \n",
       "46                               NaN                    Positive emotion   \n",
       "...                              ...                                 ...   \n",
       "8925  Other Apple product or service                    Positive emotion   \n",
       "8945              iPad or iPhone App                    Positive emotion   \n",
       "8963                     Android App                    Positive emotion   \n",
       "8982                             NaN  No emotion toward brand or product   \n",
       "9092                             NaN  No emotion toward brand or product   \n",
       "\n",
       "                                                                                                                                                    cleaned  \n",
       "38                                  @mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW  \n",
       "41                         HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android: Whether youÛªre getting friend... {link}  \n",
       "42                        Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!  \n",
       "45                                             #IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW  \n",
       "46                                                              Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}  \n",
       "...                                                                                                                                                     ...  \n",
       "8925                                         umm that would be @mention ÛÏ@mention I keep winning shit! Thanks @mention for the killer iPad case. #sxswÛ  \n",
       "8945                       FestivalExplorer iPhone App Finally Solves SXSW {link} #music #musica #musiek #musique #musik #app #sxsw #Ù_¾¬â #Ù_¾´_ #Î¥É  \n",
       "8963                                                Group #Texting War Heats Up: Fast Society Launches New Android App, Updates iPhone App: #SXSWÛ_ {link}  \n",
       "8982  In case my fairy god mother = reading mail; my ÌÙ±G wish this week is 2 go 2 #sxsw Ï for the #Android ÏÎ Dev Ïà Meetup. @mention Hilton, Sat....  \n",
       "9092                                               Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}  \n",
       "\n",
       "[485 rows x 4 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for non-ASCII characters\n",
    "# regex from https://stackoverflow.com/questions/2124010/grep-regex-to-match-non-ascii-characters\n",
    "\n",
    "df[df['tweet_text'].str.contains('[^\\x00-\\x7F]+')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:18.503591Z",
     "start_time": "2021-06-15T23:11:18.342987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPIN Play - a new concept in music discovery for your iPad from @mention &amp; spin.com {link} #iTunes #sxsw @mention'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = df.at[37, 'tweet_text']\n",
    "doc = doc.encode('ascii', 'ignore').decode()\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem I have with the non-ASCII characters is that they often seem to represent apostrophes and quotation marks. I can't find an encoding that will show them properly in python, or in a SublimeText when I open the raw file. \n",
    "\n",
    "For now I'm going to replace the non-ASCII characters with spaces because I think replacing them with nothing will lead to weird words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:18.645745Z",
     "start_time": "2021-06-15T23:11:18.515187Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_docs1(doc):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # unescape HTML characters\n",
    "    doc = html.unescape(doc)\n",
    "    \n",
    "    # remove URLs and links, replacing them with existing placeholder\n",
    "    urls = re.findall(\"http[^ ]+|www\\.[^ ]+\", doc)\n",
    "    for url in urls:\n",
    "        doc = str.replace(doc, url, '{link}')\n",
    "    \n",
    "    # replace non-ASCII characters with space\n",
    "    doc = re.sub(r\"[^\\x00-\\x7F]+\", ' ', doc)\n",
    "    \n",
    "    # replace ASCII control characters with space\n",
    "    doc = re.sub(r\"[\\x00-\\x1F]\", ' ', doc)\n",
    "    \n",
    "    # remove multiple spaces, which will exist after all this replacing words\n",
    "    doc = re.sub(r\"[ ]{2,}\", ' ', doc)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:19.014081Z",
     "start_time": "2021-06-15T23:11:18.653828Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead! I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link} #google #circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\" #sxsw #health2dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>_ _ _ RT @mention Google Tests Check-in Offers At #SXSW {link}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9088                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9089                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9090  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9091       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9092                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                 product                             emotion  \\\n",
       "0                 iPhone                    Negative emotion   \n",
       "1     iPad or iPhone App                    Positive emotion   \n",
       "2                   iPad                    Positive emotion   \n",
       "3     iPad or iPhone App                    Negative emotion   \n",
       "4                 Google                    Positive emotion   \n",
       "...                  ...                                 ...   \n",
       "9088                iPad                    Positive emotion   \n",
       "9089                 NaN  No emotion toward brand or product   \n",
       "9090                 NaN  No emotion toward brand or product   \n",
       "9091                 NaN  No emotion toward brand or product   \n",
       "9092                 NaN  No emotion toward brand or product   \n",
       "\n",
       "                                                                                                                                          cleaned  \n",
       "0                  .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead! I need to upgrade. Plugin stations at #SXSW.  \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW  \n",
       "2                                                                 @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.  \n",
       "3                                                              @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw  \n",
       "4                 @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) & Matt Mullenweg (Wordpress)  \n",
       "...                                                                                                                                           ...  \n",
       "9088                                                                                                                Ipad everywhere. #SXSW {link}  \n",
       "9089                 Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link} #google #circles  \n",
       "9090      Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\" #sxsw #health2dev  \n",
       "9091  Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended #SXSW.  \n",
       "9092                                                                               _ _ _ RT @mention Google Tests Check-in Offers At #SXSW {link}  \n",
       "\n",
       "[9092 rows x 4 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map doc cleaning function onto 'cleaned' column\n",
    "df['cleaned'] = df['cleaned'].map(lambda x: clean_docs1(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:19.119906Z",
     "start_time": "2021-06-15T23:11:19.018882Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text    Saw a company today ready to launch, sounds a lot like Google Circles, but with actual personal privacy www.mycube.com #sxsw\n",
       "product                                                                                                    Other Google product or service\n",
       "emotion                                                                                                 No emotion toward brand or product\n",
       "cleaned               Saw a company today ready to launch, sounds a lot like Google Circles, but with actual personal privacy {link} #sxsw\n",
       "Name: 7350, dtype: object"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specifically check on a few rows\n",
    "df.loc[8982]\n",
    "df.loc[7350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:19.233399Z",
     "start_time": "2021-06-15T23:11:19.125871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\""
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = df['cleaned'].loc[1]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:19.362953Z",
     "start_time": "2021-06-15T23:11:19.248473Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pattern_hits(doc, pattern, out_type):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # determine the variable type for recording hits\n",
    "    if out_type=='list': \n",
    "        hits = []\n",
    "    elif out_type=='bool':\n",
    "        hits = False\n",
    "    elif out_type=='none':\n",
    "        hits = None\n",
    "        \n",
    "    # search for regex pattern in doc\n",
    "    pattern_hits = re.findall(pattern, doc)\n",
    "\n",
    "    if len(pattern_hits) > 0:\n",
    "        # replace the hits in the original doc string\n",
    "        # need to use the re version otherwise substrings won't be replaced \n",
    "        # correctly!\n",
    "        doc = re.sub(pattern, ' ', doc)\n",
    "\n",
    "        # replace multiple spaces with a single space\n",
    "        doc = re.sub(r\"(\\s{2,})\", ' ', doc)\n",
    "\n",
    "        # Update appropriate hits variable\n",
    "        for hit in pattern_hits:\n",
    "            if out_type=='list':\n",
    "                hits.append(hit)\n",
    "            elif out_type=='bool':\n",
    "                hits = True\n",
    "\n",
    "        if out_type=='list':\n",
    "            hits = list(set(hits))\n",
    "                 \n",
    "    return doc, hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:19.480515Z",
     "start_time": "2021-06-15T23:11:19.373591Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_remove(df, doc_col, hit_col, pattern, out_type='list'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    \n",
    "    # loop through each row in the dataframe to process its record\n",
    "    for i in df.index:\n",
    "        new_doc, hits = get_pattern_hits(df.at[i, doc_col], pattern, out_type)\n",
    "        updates.append([new_doc, hits])\n",
    "    \n",
    "    df_new = pd.DataFrame(updates, columns=[doc_col, hit_col])\n",
    "    \n",
    "    if out_type=='none':\n",
    "        df_new.drop(columns=[hit_col], inplace=True)\n",
    "    \n",
    "    df = df.join(df_new, lsuffix='_old', how='inner')\n",
    "    df.drop(columns=[f\"{doc_col}_old\"], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:19.843297Z",
     "start_time": "2021-06-15T23:11:19.496639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead! I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>[@fludapp, @jessedee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>[@swonderlin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>[@sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>[@sxtxstate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>Wave, buzz... RT We interrupt your regularly scheduled #sxsw geek programming with big news {link} #google #circles</td>\n",
       "      <td>[@mention]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\" #sxsw #health2dev</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>_ _ _ RT Google Tests Check-in Offers At #SXSW {link}</td>\n",
       "      <td>[@mention]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9087                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9088                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9089  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9090       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9091                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                                                                                                                                          cleaned  \\\n",
       "0                  .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead! I need to upgrade. Plugin stations at #SXSW.   \n",
       "1                        Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                             Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                            great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) & Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                           ...   \n",
       "9087                                                                                                                Ipad everywhere. #SXSW {link}   \n",
       "9088                          Wave, buzz... RT We interrupt your regularly scheduled #sxsw geek programming with big news {link} #google #circles   \n",
       "9089      Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\" #sxsw #health2dev   \n",
       "9090  Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended #SXSW.   \n",
       "9091                                                                                        _ _ _ RT Google Tests Check-in Offers At #SXSW {link}   \n",
       "\n",
       "                   mentions  \n",
       "0                        []  \n",
       "1     [@fludapp, @jessedee]  \n",
       "2             [@swonderlin]  \n",
       "3                   [@sxsw]  \n",
       "4              [@sxtxstate]  \n",
       "...                     ...  \n",
       "9087                     []  \n",
       "9088             [@mention]  \n",
       "9089                     []  \n",
       "9090                     []  \n",
       "9091             [@mention]  \n",
       "\n",
       "[9092 rows x 3 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean and log @mentions\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = log_remove(df, doc_col='cleaned', hit_col='mentions', \n",
    "                pattern=r\"(?:^|\\s)(@[a-zA-Z0-9_-]+)\")\n",
    "df[['tweet_text', 'cleaned', 'mentions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:20.310804Z",
     "start_time": "2021-06-15T23:11:19.866506Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .</td>\n",
       "      <td>[#SXSW, #RISE_Austin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Can not wait for 2 also. They should sale them down at .</td>\n",
       "      <td>[#SXSW, #iPad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>I hope this year's festival isn't as crashy as this year's iPhone app.</td>\n",
       "      <td>[#sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Ipad everywhere. {link}</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>Wave, buzz... RT We interrupt your regularly scheduled geek programming with big news {link}</td>\n",
       "      <td>[#google, #circles, #sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"</td>\n",
       "      <td>[#health2dev, #sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>_ _ _ RT Google Tests Check-in Offers At {link}</td>\n",
       "      <td>[#SXSW]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9087                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9088                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9089  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9090       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9091                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                                                                                                                                     cleaned  \\\n",
       "0                              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .   \n",
       "1                        Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at    \n",
       "2                                                                                   Can not wait for 2 also. They should sale them down at .   \n",
       "3                                                                    I hope this year's festival isn't as crashy as this year's iPhone app.    \n",
       "4                            great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) & Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                      ...   \n",
       "9087                                                                                                                 Ipad everywhere. {link}   \n",
       "9088                                           Wave, buzz... RT We interrupt your regularly scheduled geek programming with big news {link}    \n",
       "9089                  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"    \n",
       "9090  Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .   \n",
       "9091                                                                                         _ _ _ RT Google Tests Check-in Offers At {link}   \n",
       "\n",
       "                        hashtags  \n",
       "0          [#SXSW, #RISE_Austin]  \n",
       "1                        [#SXSW]  \n",
       "2                 [#SXSW, #iPad]  \n",
       "3                        [#sxsw]  \n",
       "4                        [#SXSW]  \n",
       "...                          ...  \n",
       "9087                     [#SXSW]  \n",
       "9088  [#google, #circles, #sxsw]  \n",
       "9089        [#health2dev, #sxsw]  \n",
       "9090                     [#SXSW]  \n",
       "9091                     [#SXSW]  \n",
       "\n",
       "[9092 rows x 3 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean and remove hashtags\n",
    "df = log_remove(df, 'cleaned', 'hashtags', \n",
    "                pattern=r\"(?:^|\\s)(#[a-zA-Z0-9_-]+)\")\n",
    "df[['tweet_text', 'cleaned', 'hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:20.705203Z",
     "start_time": "2021-06-15T23:11:20.315062Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Can not wait for 2 also. They should sale them down at .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>I hope this year's festival isn't as crashy as this year's iPhone app.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Ipad everywhere.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>Wave, buzz... RT We interrupt your regularly scheduled geek programming with big news</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>_ _ _ RT Google Tests Check-in Offers At</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9087                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9088                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9089  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9090       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9091                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                                                                                                                                     cleaned  \\\n",
       "0                              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .   \n",
       "1                        Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at    \n",
       "2                                                                                   Can not wait for 2 also. They should sale them down at .   \n",
       "3                                                                    I hope this year's festival isn't as crashy as this year's iPhone app.    \n",
       "4                            great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) & Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                      ...   \n",
       "9087                                                                                                                       Ipad everywhere.    \n",
       "9088                                                  Wave, buzz... RT We interrupt your regularly scheduled geek programming with big news    \n",
       "9089                  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"    \n",
       "9090  Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .   \n",
       "9091                                                                                               _ _ _ RT Google Tests Check-in Offers At    \n",
       "\n",
       "      links  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "...     ...  \n",
       "9087   True  \n",
       "9088   True  \n",
       "9089  False  \n",
       "9090  False  \n",
       "9091   True  \n",
       "\n",
       "[9092 rows x 3 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean and remove {link} placeholders\n",
    "df = log_remove(df, 'cleaned', 'links', pattern=r\"(?:^|\\s)(\\{link\\})\", \n",
    "                out_type='bool')\n",
    "df[['tweet_text', 'cleaned', 'links']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:21.147908Z",
     "start_time": "2021-06-15T23:11:20.710564Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Can not wait for 2 also. They should sale them down at .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>I hope this year's festival isn't as crashy as this year's iPhone app.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Ipad everywhere.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>Wave, buzz... We interrupt your regularly scheduled geek programming with big news</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>_ _ _ Google Tests Check-in Offers At</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9087                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9088                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9089  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9090       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9091                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                                                                                                                                     cleaned  \\\n",
       "0                              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .   \n",
       "1                        Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at    \n",
       "2                                                                                   Can not wait for 2 also. They should sale them down at .   \n",
       "3                                                                    I hope this year's festival isn't as crashy as this year's iPhone app.    \n",
       "4                            great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) & Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                      ...   \n",
       "9087                                                                                                                       Ipad everywhere.    \n",
       "9088                                                     Wave, buzz... We interrupt your regularly scheduled geek programming with big news    \n",
       "9089                  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"    \n",
       "9090  Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .   \n",
       "9091                                                                                                  _ _ _ Google Tests Check-in Offers At    \n",
       "\n",
       "         RT  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "...     ...  \n",
       "9087  False  \n",
       "9088   True  \n",
       "9089  False  \n",
       "9090  False  \n",
       "9091   True  \n",
       "\n",
       "[9092 rows x 3 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean and remove RT placeholders\n",
    "df = log_remove(df, 'cleaned', 'RT', pattern=r\"(?:^|\\s)\\b(RT)\\b\", out_type='bool')\n",
    "df[['tweet_text', 'cleaned', 'RT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:11:37.214747Z",
     "start_time": "2021-06-15T23:11:36.978171Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Can not wait for also. They should sale them down at .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>I hope this year's festival isn't as crashy as this year's iPhone app.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Ipad everywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>Wave, buzz... We interrupt your regularly scheduled geek programming with big news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}</td>\n",
       "      <td>_ _ _ Google Tests Check-in Offers At</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "9087                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "9088                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "9089  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "9090       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "9091                                           Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @mention Google Tests ÛÏCheck-in OffersÛ At #SXSW {link}   \n",
       "\n",
       "                                                                                                                                     cleaned  \n",
       "0                                .@wesley83 I have a 3G iPhone. After hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .  \n",
       "1                        Know about ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at   \n",
       "2                                                                                     Can not wait for also. They should sale them down at .  \n",
       "3                                                                    I hope this year's festival isn't as crashy as this year's iPhone app.   \n",
       "4                            great stuff on Fri : Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) & Matt Mullenweg (Wordpress)  \n",
       "...                                                                                                                                      ...  \n",
       "9087                                                                                                                       Ipad everywhere.   \n",
       "9088                                                     Wave, buzz... We interrupt your regularly scheduled geek programming with big news   \n",
       "9089                  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. \"We're operating w/out data.\"   \n",
       "9090  Some Verizon iPhone customers complained their time fell back an hour this weekend. Of course they were the New Yorkers who attended .  \n",
       "9091                                                                                                  _ _ _ Google Tests Check-in Offers At   \n",
       "\n",
       "[9092 rows x 2 columns]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove numbers\n",
    "df = log_remove(df, 'cleaned', 'none', \n",
    "                pattern=r\"(?:^|\\s)([.:$%]*[0-9]+[.:$%]*[0-9]*)\\b\", \n",
    "                out_type='none')\n",
    "df[['tweet_text', 'cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:12:10.985764Z",
     "start_time": "2021-06-15T23:12:10.761808Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicamiles/opt/anaconda3/envs/learn-env2/lib/python3.8/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>Can not wait for also. They should sale them down at .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp;amp; Foursquare have up their sleeves at #SXSW</td>\n",
       "      <td>Really enjoying the changes in Gowalla for Android! Looking forward to seeing what else they &amp; Foursquare have up their sleeves at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>They were right, the @gowalla 3 app on #android is sweeeeet! Nice job by the team there. #sxsw</td>\n",
       "      <td>They were right, the app on is sweeeeet! Nice job by the team there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}</td>\n",
       "      <td>Mashable! - The iPad Takes Over SXSW [VIDEO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9051</th>\n",
       "      <td>@mention You could buy a new iPad 2 tmrw at the Apple pop-up store at #sxsw: {link}</td>\n",
       "      <td>You could buy a new iPad tmrw at the Apple pop-up store at :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9053</th>\n",
       "      <td>Guys, if you ever plan on attending #SXSW, you need 4 things, skinny jeans, flannel shirt, beard and an iPad #imanoutcast...</td>\n",
       "      <td>Guys, if you ever plan on attending , you need things, skinny jeans, flannel shirt, beard and an iPad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>@mention You should get the iPad 2  to save your back from lugging the laptop #SXSW #SXSWMyMistake</td>\n",
       "      <td>You should get the iPad to save your back from lugging the laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>@mention your iPhone 4 cases are Rad and Ready! Stop by tomorrow to get them! #Sxsw #zazzlesxsw #sxswi {link}</td>\n",
       "      <td>your iPhone cases are Rad and Ready! Stop by tomorrow to get them!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9075</th>\n",
       "      <td>At &amp;quot;Your Mom Has an iPad&amp;quot; session at #SXSW (@mention ACC - Ballroom B w/ 23 others) {link}</td>\n",
       "      <td>At \"Your Mom Has an iPad\" session at (@mention ACC - Ballroom B w/ others)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1667 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            tweet_text  \\\n",
       "0                      .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "2                                                                      @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "23    Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp; Foursquare have up their sleeves at #SXSW   \n",
       "28                                                      They were right, the @gowalla 3 app on #android is sweeeeet! Nice job by the team there. #sxsw   \n",
       "42                                                                          Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}   \n",
       "...                                                                                                                                                ...   \n",
       "9051                                                               @mention You could buy a new iPad 2 tmrw at the Apple pop-up store at #sxsw: {link}   \n",
       "9053                      Guys, if you ever plan on attending #SXSW, you need 4 things, skinny jeans, flannel shirt, beard and an iPad #imanoutcast...   \n",
       "9062                                                @mention You should get the iPad 2  to save your back from lugging the laptop #SXSW #SXSWMyMistake   \n",
       "9071                                     @mention your iPhone 4 cases are Rad and Ready! Stop by tomorrow to get them! #Sxsw #zazzlesxsw #sxswi {link}   \n",
       "9075                                              At &quot;Your Mom Has an iPad&quot; session at #SXSW (@mention ACC - Ballroom B w/ 23 others) {link}   \n",
       "\n",
       "                                                                                                                                  cleaned  \n",
       "0                             .@wesley83 I have a 3G iPhone. After hrs tweeting at , it was dead! I need to upgrade. Plugin stations at .  \n",
       "2                                                                                  Can not wait for also. They should sale them down at .  \n",
       "23    Really enjoying the changes in Gowalla for Android! Looking forward to seeing what else they & Foursquare have up their sleeves at   \n",
       "28                                                                  They were right, the app on is sweeeeet! Nice job by the team there.   \n",
       "42                                                                                          Mashable! - The iPad Takes Over SXSW [VIDEO]   \n",
       "...                                                                                                                                   ...  \n",
       "9051                                                                        You could buy a new iPad tmrw at the Apple pop-up store at :   \n",
       "9053                            Guys, if you ever plan on attending , you need things, skinny jeans, flannel shirt, beard and an iPad ...  \n",
       "9062                                                                   You should get the iPad to save your back from lugging the laptop   \n",
       "9071                                                                  your iPhone cases are Rad and Ready! Stop by tomorrow to get them!   \n",
       "9075                                                          At \"Your Mom Has an iPad\" session at (@mention ACC - Ballroom B w/ others)   \n",
       "\n",
       "[1667 rows x 2 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I don't see any numbers in the initial cells, so let's find some\n",
    "df.loc[df['tweet_text'].str.contains(r\"(?:^|\\s)([.:$%]*[0-9]+[.:$%]*[0-9]*)\\s\"), \n",
    "       ['tweet_text', 'cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:12:23.638389Z",
     "start_time": "2021-06-15T23:12:23.546571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>links</th>\n",
       "      <th>RT</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at . Not sure if I'll need to Q up at an Austin Apple store?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>@mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &amp;quot;flash store&amp;quot; downtown to sell iPad2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[@mention]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>- Great weather to greet you for ! Still need a sweater at night..Apple putting up \"flash store\" downtown to sell iPad2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>iPad2? RT @mention Droid &amp;amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp;amp; blackberry to follow #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[@mention]</td>\n",
       "      <td>[#SXSW, #agnerd]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>iPad2? Droid &amp; Mac here :) My confession, using laptop, iPad &amp; blackberry to follow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>#fastball #sxsw Giving away two NEW Ipad2 wifi 32g black Apple cover tweet @mention fo more info #sxswi #attsxsw  Tonight @mention bo.lt house</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[@mention]</td>\n",
       "      <td>[#fastball, #sxswi, #sxsw, #attsxsw]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Giving away two NEW Ipad2 wifi 32g black Apple cover tweet fo more info Tonight bo.lt house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ipad2 and #sxsw...a conflagration of doofusness.  {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ipad2 and ...a conflagration of doofusness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>#japan #SXSW put you collective entrepreneurial and social minds and iPad 2s together and do something for Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#SXSW, #japan]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>put you collective entrepreneurial and social minds and iPad 2s together and do something for Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>Getting my ipad2 #sxsw (@mention Apple Store w/ 4 others) {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Getting my ipad2 (@mention Apple Store w/ others)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>Second day using my Apple iPad2 at #SXSW and I'm really impressed. The magnetic cover is pure brilliance. Using a laptop is so old school.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#SXSW]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Second day using my Apple iPad2 at and I'm really impressed. The magnetic cover is pure brilliance. Using a laptop is so old school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9057</th>\n",
       "      <td>&amp;quot;Do you know what Apple is really good at? Making you feel bad about your Xmas present!&amp;quot; - Seth Meyers on iPad2 #sxsw #doyoureallyneedthat?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can't tell</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#doyoureallyneedthat, #sxsw]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>\"Do you know what Apple is really good at? Making you feel bad about your Xmas present!\" - Seth Meyers on iPad2 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>@mention you should find @mention or...you can go purchase the new ipad2 at the #sxsw apple kiosk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[@mention]</td>\n",
       "      <td>[#sxsw]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>you should find or...you can go purchase the new ipad2 at the apple kiosk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 tweet_text  \\\n",
       "19                                               Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?   \n",
       "39         @mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &quot;flash store&quot; downtown to sell iPad2   \n",
       "77                        iPad2? RT @mention Droid &amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp; blackberry to follow #SXSW   \n",
       "146          #fastball #sxsw Giving away two NEW Ipad2 wifi 32g black Apple cover tweet @mention fo more info #sxswi #attsxsw  Tonight @mention bo.lt house   \n",
       "171                                                                                                ipad2 and #sxsw...a conflagration of doofusness.  {link}   \n",
       "...                                                                                                                                                     ...   \n",
       "8959                                       #japan #SXSW put you collective entrepreneurial and social minds and iPad 2s together and do something for Japan   \n",
       "8995                                                                                       Getting my ipad2 #sxsw (@mention Apple Store w/ 4 others) {link}   \n",
       "9017             Second day using my Apple iPad2 at #SXSW and I'm really impressed. The magnetic cover is pure brilliance. Using a laptop is so old school.   \n",
       "9057  &quot;Do you know what Apple is really good at? Making you feel bad about your Xmas present!&quot; - Seth Meyers on iPad2 #sxsw #doyoureallyneedthat?   \n",
       "9061                                                      @mention you should find @mention or...you can go purchase the new ipad2 at the #sxsw apple kiosk   \n",
       "\n",
       "     product                             emotion    mentions  \\\n",
       "19      iPad                    Positive emotion          []   \n",
       "39     Apple                    Positive emotion  [@mention]   \n",
       "77       NaN  No emotion toward brand or product  [@mention]   \n",
       "146      NaN  No emotion toward brand or product  [@mention]   \n",
       "171     iPad                    Negative emotion          []   \n",
       "...      ...                                 ...         ...   \n",
       "8959     NaN  No emotion toward brand or product          []   \n",
       "8995    iPad                    Positive emotion          []   \n",
       "9017    iPad                    Positive emotion          []   \n",
       "9057     NaN                        I can't tell          []   \n",
       "9061     NaN  No emotion toward brand or product  [@mention]   \n",
       "\n",
       "                                  hashtags  links     RT  \\\n",
       "19                                 [#sxsw]  False  False   \n",
       "39                                 [#sxsw]  False  False   \n",
       "77                        [#SXSW, #agnerd]  False   True   \n",
       "146   [#fastball, #sxswi, #sxsw, #attsxsw]  False  False   \n",
       "171                                [#sxsw]   True  False   \n",
       "...                                    ...    ...    ...   \n",
       "8959                       [#SXSW, #japan]  False  False   \n",
       "8995                               [#sxsw]   True  False   \n",
       "9017                               [#SXSW]  False  False   \n",
       "9057         [#doyoureallyneedthat, #sxsw]  False  False   \n",
       "9061                               [#sxsw]  False  False   \n",
       "\n",
       "                                                                                                                                   cleaned  \n",
       "19                                   Need to buy an iPad2 while I'm in Austin at . Not sure if I'll need to Q up at an Austin Apple store?  \n",
       "39                 - Great weather to greet you for ! Still need a sweater at night..Apple putting up \"flash store\" downtown to sell iPad2  \n",
       "77                                                    iPad2? Droid & Mac here :) My confession, using laptop, iPad & blackberry to follow   \n",
       "146                                            Giving away two NEW Ipad2 wifi 32g black Apple cover tweet fo more info Tonight bo.lt house  \n",
       "171                                                                                           ipad2 and ...a conflagration of doofusness.   \n",
       "...                                                                                                                                    ...  \n",
       "8959                                   put you collective entrepreneurial and social minds and iPad 2s together and do something for Japan  \n",
       "8995                                                                                    Getting my ipad2 (@mention Apple Store w/ others)   \n",
       "9017  Second day using my Apple iPad2 at and I'm really impressed. The magnetic cover is pure brilliance. Using a laptop is so old school.  \n",
       "9057                     \"Do you know what Apple is really good at? Making you feel bad about your Xmas present!\" - Seth Meyers on iPad2 ?  \n",
       "9061                                                             you should find or...you can go purchase the new ipad2 at the apple kiosk  \n",
       "\n",
       "[374 rows x 8 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for standalone 2's, which I found after processing a little further.\n",
    "# needed to adjust the regex to accomodate numbers at the end of the doc\n",
    "# or end of a sentence\n",
    "df[df['cleaned'].str.contains(r\"2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T19:14:35.130711Z",
     "start_time": "2021-06-15T19:14:34.969109Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave, buzz... RT  We interrupt your regularly scheduled #sxsw geek programming with big news {link} #google #circles\n"
     ]
    }
   ],
   "source": [
    "doc = \"Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link} #google #circles\"\n",
    "\n",
    "# pattern=r\"[\\x01-\\x1F]\"\n",
    "# pattern_hits = re.findall(pattern, doc)\n",
    "\n",
    "# # replace the hits in the original doc string\n",
    "# for hit in pattern_hits:\n",
    "#     print(hit)\n",
    "    \n",
    "# replace all instances\n",
    "doc = re.sub(r\"(?:^|\\s)(@[a-zA-Z0-9_-]+)\", \" \", doc, )\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tokenized corpora for visualization\n",
    "\n",
    "I'm going to write a function to remove the stopwords (and punctuation), as well as tokenize using lemmatization or not. This will allow me to use it ad-hoc to generate tokens for the entire corpus for EDA before modeling, and also use it in an sklearn pipeline so I can apply the same logic when pre-processing for modeling.\n",
    "\n",
    "I concerned that some of the stop words in the default nltk list, such as negations (don't, won't, shouldn't, can't) might more commonly contribute to negative emotion than positive ones. I want to investigate the list of stopwords and check out what I might want to customize. I may try a few different iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:16:10.797981Z",
     "start_time": "2021-06-15T21:16:10.420822Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords = stopwords.words('english')\n",
    "nltk_stopwords.sort()\n",
    "print(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:08:43.697322Z",
     "start_time": "2021-06-15T21:08:43.469245Z"
    }
   },
   "outputs": [],
   "source": [
    "# my much-pared-down stopwords list for testing\n",
    "custom_stopwords = ['a',\n",
    "'an',\n",
    "'and',\n",
    "'as',\n",
    "'at',\n",
    "'be',\n",
    "'by',\n",
    "'for',\n",
    "'from',\n",
    "'if',\n",
    "'in',\n",
    "'into',\n",
    "'it',\n",
    "\"it's\",\n",
    "'its',\n",
    "'itself',\n",
    "'of',\n",
    "'on',\n",
    "'or',\n",
    "'than',\n",
    "'that',\n",
    "\"that'll\",\n",
    "'the',\n",
    "'to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:00:52.119763Z",
     "start_time": "2021-06-15T22:00:52.053781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
      "['\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# create full and custom punctuation list. Custom excludes ! and ?\n",
    "punc = list(string.punctuation)\n",
    "punc_custom = punc.copy()\n",
    "punc_custom.remove('?')\n",
    "punc_custom.remove('!')\n",
    "\n",
    "print(punc)\n",
    "print(punc_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T21:33:51.124866Z",
     "start_time": "2021-06-15T21:33:51.050538Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No emotion toward brand or product',\n",
       " 'Positive emotion',\n",
       " 'Negative emotion',\n",
       " \"I can't tell\"]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of all the emotions\n",
    "all_emotions = list(df['emotion'].value_counts().index)\n",
    "all_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:33:06.538283Z",
     "start_time": "2021-06-15T22:33:05.451460Z"
    }
   },
   "outputs": [],
   "source": [
    "# running this outside the function to avoid re-instantiating it each time,\n",
    "# which takes longer\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:11:18.006606Z",
     "start_time": "2021-06-16T00:11:17.923216Z"
    }
   },
   "outputs": [],
   "source": [
    "def spacy_tokenizer(doc, stop_list=None, lemmatize=True, orig_pronouns=True):\n",
    "    \"\"\"\n",
    "    Tokenizes a string of text (document) with optional stop word removal\n",
    "    and lemmatization from SpaCy. Add punctuation to `stop_list` to remove it \n",
    "    too, otherwise it will be retained as separate words based on how SpaCy\n",
    "    parses it (some may remain attached to words).\n",
    "    \n",
    "    Always lowercases text.\n",
    "    \n",
    "    Returns a list of tokenized words, lowercased, lemmatized and with stopwords\n",
    "    removed as indicated.\n",
    "    \n",
    "    ******\n",
    "    Arguments:\n",
    "    ******\n",
    "    \n",
    "    doc: String representing a document to be tokenized.\n",
    "    \n",
    "    stop_list: List of stop words to remove, or `None` to not remove any words.\n",
    "    Add punctuation to this list to remove it.\n",
    "    \n",
    "    lemmatize: Boolean, default True. Set to False to use original versions of\n",
    "    words instead of lemmas.\n",
    "    \n",
    "    orig_pronouns: Boolean, default True. Only applicable if you are lemmatizing.\n",
    "    If True, use the original version of personal pronouns such as \"I\", \"you\", \n",
    "    \"your\" instead of the `-PRON-` placeholder that SpaCy adds to standardize \n",
    "    these. If False, include the `-PRON-` placeholder as the literal text token.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use SpaCy to tokenize the doc\n",
    "    tokens = nlp(doc)\n",
    "    \n",
    "    new_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        new_token = ''\n",
    "        \n",
    "        # determine appropriate version of token to use\n",
    "        if lemmatize:\n",
    "            \n",
    "            if token.lemma_ == '-PRON-':\n",
    "                if orig_pronouns:\n",
    "                    new_token = str.lower(token.text)\n",
    "                else:\n",
    "                    new_token = str.lower(token.lemma_)\n",
    "            else:\n",
    "                new_token = str.lower(token.lemma_)\n",
    "        else:\n",
    "            new_token = str.lower(token.text)\n",
    "        \n",
    "        # check token against stop word list, if using\n",
    "        if not stop_list == None:\n",
    "            if new_token not in stop_list:\n",
    "                new_tokens.append(new_token)\n",
    "            \n",
    "        else:\n",
    "            new_tokens.append(new_token)         \n",
    "\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:22:30.200192Z",
     "start_time": "2021-06-15T22:22:30.052038Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenized_corpus_dict(df, target_vals, stop_list, lemmatize, \n",
    "                          orig_pronouns, verbose=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # generate corpus for each emotion\n",
    "    corpus_per_target = {}\n",
    "\n",
    "    for val in target_vals:\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Starting target val: {val}\")\n",
    "\n",
    "        # get series of text docs per target_val\n",
    "        docs = df.loc[df['emotion']==val, 'cleaned']\n",
    "\n",
    "        # loop through docs and tokenize each one\n",
    "        corpus = []\n",
    "\n",
    "        i = 0\n",
    "        for doc in docs:\n",
    "            tokens = spacy_tokenizer(doc, stop_list=stop_list, \n",
    "                              lemmatize=lemmatize, orig_pronouns=True)\n",
    "            # remove words if they're just spaces!\n",
    "            tokens.remove(' ') if ' ' in tokens else None\n",
    "            \n",
    "            corpus.extend(tokens)\n",
    "            i += 1\n",
    "            \n",
    "            if verbose and (i % 1000 == 0):\n",
    "                print(f\"Processed {i} docs out of {len(docs)}...\")\n",
    "\n",
    "        # add corpus to dict\n",
    "        corpus_per_target[val] = corpus\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"Done!\")\n",
    "    return corpus_per_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:24:05.776593Z",
     "start_time": "2021-06-15T22:22:35.233893Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting target val: No emotion toward brand or product\n",
      "Processed 1000 docs out of 5388...\n",
      "Processed 2000 docs out of 5388...\n",
      "Processed 3000 docs out of 5388...\n",
      "Processed 4000 docs out of 5388...\n",
      "Processed 5000 docs out of 5388...\n",
      "Starting target val: Positive emotion\n",
      "Processed 1000 docs out of 2978...\n",
      "Processed 2000 docs out of 2978...\n",
      "Starting target val: Negative emotion\n",
      "Starting target val: I can't tell\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# remove no stopwords except most punctuation, don't lemmatize\n",
    "min_processing = tokenized_corpus_dict(df, all_emotions, stop_list=punc_custom, \n",
    "                        lemmatize=False, orig_pronouns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the results and make sure things look good. I had to go back and add a line to remove words that are just spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:21:16.734857Z",
     "start_time": "2021-06-15T22:21:16.520464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' New iPad Apps For And Communication Are Showcased At The Conference ',\n",
       "       'Holler Gram for iPad on the iTunes App Store - (via ) ',\n",
       "       'Attn: All frineds, Register for and see Cobra iRadar for Android. ',\n",
       "       'Anyone at want to sell their old iPad?',\n",
       "       'Anyone at who bought the new iPad want to sell their older iPad to me?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['emotion']==\"No emotion toward brand or product\", 'cleaned'][:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:25:32.761172Z",
     "start_time": "2021-06-15T22:25:32.648138Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new', 'ipad', 'apps', 'for', 'and', 'communication', 'are', 'showcased', 'at', 'the', 'conference', 'holler', 'gram', 'for', 'ipad', 'on', 'the', 'itunes', 'app', 'store', 'via', 'attn', 'all', 'frineds', 'register', 'for', 'and', 'see', 'cobra', 'iradar', 'for', 'android', 'anyone', 'at', 'want', 'to', 'sell', 'their', 'old', 'ipad', '?', 'anyone', 'at', 'who', 'bought', 'the', 'new', 'ipad', 'want', 'to', 'sell', 'their', 'older', 'ipad', 'to', 'me', '?', 'at', 'oooh', 'google', 'to', 'launch', 'major', 'new', 'social', 'network', 'called', 'circles', 'possibly', 'today', 'spin', 'play', 'a', 'new', 'concept', 'in', 'music', 'discovery', 'for', 'your', 'ipad', 'from', 'spin.com', 'vatornews', 'google', 'and', 'apple', 'force', 'print', 'media', 'to', 'evolve', '?', 'hootsuite', 'hootsuite', 'mobile', 'for', 'updates', 'for', 'iphone']\n"
     ]
    }
   ],
   "source": [
    "print(min_processing[\"No emotion toward brand or product\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T22:30:06.843542Z",
     "start_time": "2021-06-15T22:30:06.634512Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ipad</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>store</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'s</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>iphone</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>up</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>on</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>app</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>new</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>?</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>you</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>an</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>my</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>with</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>austin</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>just</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>this</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pop</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>be</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>that</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>out</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>have</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>from</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>by</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>android</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>are</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>launch</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>get</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>they</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>n't</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sxsw</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>one</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>your</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>so</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>now</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>great</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Count\n",
       "0       the   1597\n",
       "1         !   1250\n",
       "2        to   1161\n",
       "3        at   1013\n",
       "4      ipad    932\n",
       "5       for    909\n",
       "6         a    789\n",
       "7     apple    755\n",
       "8    google    663\n",
       "9        is    654\n",
       "10       in    639\n",
       "11       of    639\n",
       "12        i    633\n",
       "13      and    579\n",
       "14    store    547\n",
       "15       's    493\n",
       "16       it    477\n",
       "17   iphone    462\n",
       "18       up    461\n",
       "19       on    442\n",
       "20      app    385\n",
       "21      new    359\n",
       "22        ?    338\n",
       "23      you    335\n",
       "24       an    330\n",
       "25       my    306\n",
       "26     with    296\n",
       "27   austin    257\n",
       "28     just    242\n",
       "29     this    226\n",
       "30      pop    214\n",
       "31       be    205\n",
       "32      ...    204\n",
       "33     that    197\n",
       "34      out    192\n",
       "35     have    184\n",
       "36     from    174\n",
       "37       by    172\n",
       "38  android    161\n",
       "39      are    159\n",
       "40   launch    159\n",
       "41      get    158\n",
       "42     they    151\n",
       "43      n't    151\n",
       "44     sxsw    150\n",
       "45      one    148\n",
       "46     your    147\n",
       "47       so    145\n",
       "48      now    142\n",
       "49    great    137"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out most common words\n",
    "pos_min = FreqDist(min_processing['Positive emotion'])\n",
    "\n",
    "\n",
    "freq_df = pd.DataFrame(pos_min.most_common(50),columns=['Word','Count'])\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this minimally processed, tokenized corpus, I expect to still see stop words, ? and !, but definitely looking for other words or symbols that stand out, which I want to add to the stop words list.\n",
    "\n",
    "Product names such as `apple`, `ipad`, `android`, and `google` stand out, as well as `austin` and `sxsw`, since I think these tweets were taken from a set where the SXSW festival in Austin was tagged. \n",
    "\n",
    "Also the ellipsis, which I realize wasn't in the punctuation list.\n",
    "\n",
    "I'm going to add the ellipsis to the punctuation lists, and create another stop words list for products that I can test removing or leaving in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:00:19.493182Z",
     "start_time": "2021-06-15T23:00:19.403358Z"
    }
   },
   "outputs": [],
   "source": [
    "# add ellipsis to punctuatino list to be excluded. I actually think it's\n",
    "# being processed as a word by SpaCy, but since I'm removing both punctuation \n",
    "# and stop words at once, it shouldn't matter which list I use\n",
    "punc.append(\"...\")\n",
    "punc_custom.append(\"...\")\n",
    "\n",
    "# create additional stopword lists related to the specific product and event\n",
    "# so they can be removed separately to test results\n",
    "product_stopwords = ['ipad', 'apple', 'google', 'iphone', 'android', 'ipad2']\n",
    "event_stopwords = ['austin', 'sxsw']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T23:17:11.425217Z",
     "start_time": "2021-06-15T23:15:36.739530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting target val: No emotion toward brand or product\n",
      "Processed 1000 docs out of 5388...\n",
      "Processed 2000 docs out of 5388...\n",
      "Processed 3000 docs out of 5388...\n",
      "Processed 4000 docs out of 5388...\n",
      "Processed 5000 docs out of 5388...\n",
      "Starting target val: Positive emotion\n",
      "Processed 1000 docs out of 2978...\n",
      "Processed 2000 docs out of 2978...\n",
      "Starting target val: Negative emotion\n",
      "Starting target val: I can't tell\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Let's try this again, with the updates! I'm just going to use the updated\n",
    "# punc lists on this minimally processed version\n",
    "\n",
    "min_processing = tokenized_corpus_dict(df, all_emotions, stop_list=punc_custom, \n",
    "                        lemmatize=False, orig_pronouns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:14:06.551313Z",
     "start_time": "2021-06-16T00:12:03.509959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting target val: No emotion toward brand or product\n",
      "Processed 1000 docs out of 5388...\n",
      "Processed 2000 docs out of 5388...\n",
      "Processed 3000 docs out of 5388...\n",
      "Processed 4000 docs out of 5388...\n",
      "Processed 5000 docs out of 5388...\n",
      "Starting target val: Positive emotion\n",
      "Processed 1000 docs out of 2978...\n",
      "Processed 2000 docs out of 2978...\n",
      "Starting target val: Negative emotion\n",
      "Starting target val: I can't tell\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# remove pared down and event stopwords as well as most punctuation, \n",
    "# lemmatize, and use '-pron-' placeholder\n",
    "med_processing = tokenized_corpus_dict(df, all_emotions, \n",
    "            stop_list=custom_stopwords + punc_custom + event_stopwords, \n",
    "            lemmatize=True, orig_pronouns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:15:55.419448Z",
     "start_time": "2021-06-16T00:14:06.644575Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting target val: No emotion toward brand or product\n",
      "Processed 1000 docs out of 5388...\n",
      "Processed 2000 docs out of 5388...\n",
      "Processed 3000 docs out of 5388...\n",
      "Processed 4000 docs out of 5388...\n",
      "Processed 5000 docs out of 5388...\n",
      "Starting target val: Positive emotion\n",
      "Processed 1000 docs out of 2978...\n",
      "Processed 2000 docs out of 2978...\n",
      "Starting target val: Negative emotion\n",
      "Starting target val: I can't tell\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# remove full nltk stopword list, event and product stopwords and all \n",
    "# punctuation, lemmatize, and use SpaCy's pronoun placeholder instead of\n",
    "# the original text\n",
    "max_processing = tokenized_corpus_dict(df, all_emotions, \n",
    "    stop_list=nltk_stopwords + punc + event_stopwords + product_stopwords, \n",
    "    lemmatize=True, orig_pronouns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:15:55.569943Z",
     "start_time": "2021-06-16T00:15:55.429454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ipad</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>store</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>up</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iphone</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>app</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>have</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>?</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>you</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>my</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>not</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>get</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'s</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>just</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>this</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pop</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>do</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>go</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>out</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>launch</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>will</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>open</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>android</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>they</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>one</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>party</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>win</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>your</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>so</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>come</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>line</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>good</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>now</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>great</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>time</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>see</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>all</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>cool</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>day</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>use</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>social</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>about</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>we</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>free</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>like</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Count\n",
       "0         !   1250\n",
       "1      ipad    965\n",
       "2     apple    756\n",
       "3    google    663\n",
       "4         i    633\n",
       "5     store    558\n",
       "6        up    464\n",
       "7    iphone    463\n",
       "8       app    442\n",
       "9      have    392\n",
       "10      new    360\n",
       "11        ?    338\n",
       "12      you    335\n",
       "13       my    306\n",
       "14     with    296\n",
       "15      not    292\n",
       "16      get    278\n",
       "17       's    255\n",
       "18     just    242\n",
       "19     this    226\n",
       "20      pop    217\n",
       "21       do    216\n",
       "22       go    199\n",
       "23      out    192\n",
       "24   launch    190\n",
       "25     will    180\n",
       "26     open    170\n",
       "27  android    161\n",
       "28     they    151\n",
       "29      one    151\n",
       "30    party    149\n",
       "31      win    148\n",
       "32     your    147\n",
       "33       so    145\n",
       "34     come    145\n",
       "35     line    145\n",
       "36     good    142\n",
       "37      now    142\n",
       "38    great    139\n",
       "39     time    136\n",
       "40      see    136\n",
       "41      all    127\n",
       "42     cool    124\n",
       "43      day    123\n",
       "44      use    123\n",
       "45   social    122\n",
       "46    about    121\n",
       "47       we    121\n",
       "48     free    120\n",
       "49     like    120"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out most common words from positive, medium-processed corpus\n",
    "pos_med = FreqDist(med_processing['Positive emotion'])\n",
    "\n",
    "freq_df = pd.DataFrame(pos_med.most_common(50),columns=['Word','Count'])\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:15:55.713428Z",
     "start_time": "2021-06-16T00:15:55.583844Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'s</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pop</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>launch</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>open</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>party</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>win</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>come</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>line</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>great</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>see</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cool</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>use</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>social</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>free</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>like</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>via</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>today</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>love</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>check</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>circles</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>look</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>awesome</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>network</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mobile</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>make</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>temporary</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>downtown</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>thank</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>people</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>w/</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>popup</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>take</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>even</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>well</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>call</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>buy</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>want</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>around</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>need</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mayer</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>year</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Count\n",
       "0       store    558\n",
       "1         app    442\n",
       "2         new    360\n",
       "3         get    278\n",
       "4          's    255\n",
       "5         pop    217\n",
       "6          go    199\n",
       "7      launch    190\n",
       "8        open    170\n",
       "9         one    151\n",
       "10      party    149\n",
       "11        win    148\n",
       "12       come    145\n",
       "13       line    145\n",
       "14       good    142\n",
       "15      great    139\n",
       "16       time    136\n",
       "17        see    136\n",
       "18       cool    124\n",
       "19        day    123\n",
       "20        use    123\n",
       "21     social    122\n",
       "22       free    120\n",
       "23       like    120\n",
       "24        via    119\n",
       "25      today    114\n",
       "26       love    111\n",
       "27      check    102\n",
       "28    circles    101\n",
       "29       look     95\n",
       "30    awesome     92\n",
       "31    network     92\n",
       "32     mobile     92\n",
       "33       make     91\n",
       "34  temporary     89\n",
       "35   downtown     88\n",
       "36      thank     84\n",
       "37     people     83\n",
       "38         w/     79\n",
       "39      popup     77\n",
       "40       take     72\n",
       "41       even     71\n",
       "42       well     70\n",
       "43       call     70\n",
       "44        buy     69\n",
       "45       want     68\n",
       "46     around     67\n",
       "47       need     67\n",
       "48      mayer     66\n",
       "49       year     66"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out most common words from positive, max-processed corpus\n",
    "pos_max = FreqDist(max_processing['Positive emotion'])\n",
    "\n",
    "freq_df = pd.DataFrame(pos_max.most_common(50),columns=['Word','Count'])\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T00:31:34.817762Z",
     "start_time": "2021-06-16T00:31:34.509635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'s</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>go</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>launch</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>design</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>people</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>use</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>think</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>social</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>circles</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>take</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>look</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>one</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>good</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>come</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>line</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>time</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>say</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>call</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>today</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>would</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>see</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>day</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>long</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>give</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pop</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>well</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>network</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>phone</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>make</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>year</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>news</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>battery</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>may</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>product</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>talk</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>user</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>wait</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>try</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>thing</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>much</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>company</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>america</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tweet</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>back</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Count\n",
       "0       app     85\n",
       "1     store     47\n",
       "2       new     45\n",
       "3      like     43\n",
       "4       get     42\n",
       "5        's     38\n",
       "6      need     35\n",
       "7        go     33\n",
       "8    launch     31\n",
       "9    design     30\n",
       "10   people     29\n",
       "11      use     28\n",
       "12    think     28\n",
       "13   social     28\n",
       "14  circles     26\n",
       "15     take     24\n",
       "16     look     24\n",
       "17      one     23\n",
       "18     good     23\n",
       "19     come     22\n",
       "20     line     22\n",
       "21     time     22\n",
       "22      say     21\n",
       "23     call     21\n",
       "24    today     21\n",
       "25    would     21\n",
       "26      see     20\n",
       "27      day     20\n",
       "28     long     19\n",
       "29     give     18\n",
       "30      pop     18\n",
       "31     well     18\n",
       "32  network     18\n",
       "33    phone     18\n",
       "34     make     18\n",
       "35     year     17\n",
       "36     news     17\n",
       "37  battery     17\n",
       "38      may     17\n",
       "39  product     17\n",
       "40     talk     17\n",
       "41     user     16\n",
       "42     wait     15\n",
       "43      try     15\n",
       "44    thing     15\n",
       "45     much     15\n",
       "46  company     15\n",
       "47  america     15\n",
       "48    tweet     14\n",
       "49     back     14"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out most common words from positive, max-processed corpus\n",
    "neg_max = FreqDist(max_processing['Negative emotion'])\n",
    "\n",
    "freq_df = pd.DataFrame(neg_max.most_common(50),columns=['Word','Count'])\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How did you analyze or model the data?\n",
    "* How did you iterate on your initial approach to make it better?\n",
    "* Why are these choices appropriate given the data and the business problem?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for modeling\n",
    "\n",
    "A few of the options I'd like to try:\n",
    "\n",
    "Different versions of stopwords and punctuation removal. All stopwords from the default NLTK list, which I think may contain some words that will be useful, and then also my customized, pared down stopwords list.\n",
    "\n",
    "I'd like to keep contractions by default, but experiment with removing other punctuation. I'd like to try removing everything, and also keeping punctuation marks and question marks.\n",
    "\n",
    "Try stemming or lemmatization. Ideally I'd like a way to expand contractions, but I'm not sure how feasible that will be.\n",
    "\n",
    "I want to try a few different ways to vectorize. Regular `CountVectorizer` with the actual counts, TFIdF normalized, and als maybe a binary count. The [sklearn documentation mentions](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    ">\"...very short texts are likely to have noisy tf–idf values while the binary occurrence info is more stable.\"\n",
    "\n",
    "Also, probably unigrams or bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:05:55.297250Z",
     "start_time": "2021-06-15T00:05:54.981785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:07:48.384696Z",
     "start_time": "2021-06-15T00:07:48.312889Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[df['emotion'].isin(['Positive emotion', 'Negative emotion']), \n",
    "           'cleaned']\n",
    "y = df.loc[df['emotion'].isin(['Positive emotion', 'Negative emotion']), \n",
    "           'emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:09:04.626365Z",
     "start_time": "2021-06-15T00:09:04.562937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2978\n",
       "0     570\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.map(lambda x: 1 if x==\"Positive emotion\" else 0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:27:38.765878Z",
     "start_time": "2021-06-15T00:27:38.681225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838\n",
      "2838\n",
      "710\n",
      "710\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:28:13.153758Z",
     "start_time": "2021-06-15T00:28:13.090170Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.840733\n",
       "0    0.159267\n",
       "Name: emotion, dtype: float64"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:28:21.832967Z",
     "start_time": "2021-06-15T00:28:21.746773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.833803\n",
       "0    0.166197\n",
       "Name: emotion, dtype: float64"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not going to worry about stop words removal, since I plan to use TfIdf in my document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T00:29:36.533514Z",
     "start_time": "2021-06-15T00:29:35.956265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 downloads</th>\n",
       "      <th>000 louis</th>\n",
       "      <th>000 sq</th>\n",
       "      <th>000 square</th>\n",
       "      <th>000 to</th>\n",
       "      <th>000 very</th>\n",
       "      <th>02</th>\n",
       "      <th>02 symbian</th>\n",
       "      <th>03</th>\n",
       "      <th>...</th>\n",
       "      <th>zombies what</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zomg got</th>\n",
       "      <th>zomg its</th>\n",
       "      <th>zomg special</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoom in</th>\n",
       "      <th>zoom to</th>\n",
       "      <th>zzzs</th>\n",
       "      <th>zzzs iphone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows × 24770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  000 downloads  000 louis  000 sq  000 square  000 to  000 very  \\\n",
       "0     0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "1     0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "2     0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "3     0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "4     0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "...   ...            ...        ...     ...         ...     ...       ...   \n",
       "2833  0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "2834  0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "2835  0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "2836  0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "2837  0.0            0.0        0.0     0.0         0.0     0.0       0.0   \n",
       "\n",
       "       02  02 symbian   03  ...  zombies what  zomg  zomg got  zomg its  \\\n",
       "0     0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "1     0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "2     0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "3     0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "4     0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "...   ...         ...  ...  ...           ...   ...       ...       ...   \n",
       "2833  0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "2834  0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "2835  0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "2836  0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "2837  0.0         0.0  0.0  ...           0.0   0.0       0.0       0.0   \n",
       "\n",
       "      zomg special  zoom  zoom in  zoom to  zzzs  zzzs iphone  \n",
       "0              0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "1              0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "2              0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "3              0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "4              0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "...            ...   ...      ...      ...   ...          ...  \n",
       "2833           0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "2834           0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "2835           0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "2836           0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "2837           0.0   0.0      0.0      0.0   0.0          0.0  \n",
       "\n",
       "[2838 rows x 24770 columns]"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, analyzer='word', \n",
    "                             ngram_range=(1, 2))\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_train_df = pd.DataFrame(X_train_tfidf.todense(), \n",
    "                          columns=vectorizer.get_feature_names())\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNTERPRET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate how well your work solves the stated business problem.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* How do you interpret the results?\n",
    "* How well does your model fit your data? How much better is this than your baseline model?\n",
    "* How confident are you that your results would generalize beyond the data you have?\n",
    "* How confident are you that this model would benefit the business if put into use?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "***\n",
    "Questions to consider:\n",
    "* What would you recommend the business do as a result of this work?\n",
    "* What are some reasons why your analysis might not fully solve the business problem?\n",
    "* What else could you do in the future to improve this project?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One big challenge with this dataset is how applicable it would be to other products, and also to different situations. I believe all of these tweets were tagged to the SWSW festival in Austin, so the content is specific to the activities and such that were there.\n",
    "\n",
    "It's also pretty specific to Apple and Google products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env2",
   "language": "python",
   "name": "learn-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
